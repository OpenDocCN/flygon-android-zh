- en: Chapter 4. Locating in the World
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第4章. 在世界中的定位
- en: In the last chapter you learned how to overlay digital content on the view of
    the physical world. However, if you move around with your device, point it somewhere
    else, the virtual content will always stay at the same place on your screen. This
    is not exactly what happens in AR. The virtual content should stay at the same
    place relative to the physical world (and you can move around it), not remaining
    fixed on your screen.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，您学习了如何将数字内容叠加在物理世界的视图上。然而，如果您带着设备四处移动，将其指向其他地方，虚拟内容将始终停留在屏幕上的同一位置。这并不是AR中真正发生的情况。虚拟内容应该相对于物理世界保持在同一位置（你可以围绕它移动），而不是固定在屏幕上。
- en: 'In this chapter we will look at how to achieve **dynamic registration** between
    digital content and the physical space. If at every time step, we update the position
    of moving objects in our application, we will create the feeling that digital
    content sticks to the physical world. Following the position of moving elements
    in our scene can be defined as **tracking**, and this is what we will use and
    implement in this chapter. We will use sensor-based AR to update the registration
    between digital content and physical space. As some of these sensors are commonly
    of poor quality, we will show you how to improve the measurement you get from
    them using a technique named **sensor fusion**. To make it more practical, we
    will show you how to develop the basic building blocks for a simple prototype
    of one of the most common AR applications using global tracking: an AR Browser
    (such as Junaio, Layar, or Wikitude).'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨如何实现数字内容与物理空间之间的**动态注册**。如果我们每次都更新应用程序中移动对象的位置，我们将创造出数字内容与物理世界紧密相连的感觉。跟随场景中移动元素的位置可以定义为**追踪**，这正是我们将在本章中使用和实现的内容。我们将使用基于传感器的AR来更新数字内容与物理空间之间的注册。由于这些传感器通常质量不佳，我们将向您展示如何使用一种名为**传感器融合**的技术来改善从它们获得的测量结果。为了更具实用性，我们将向您展示如何开发一个简单的原型，这是最常见基于全局追踪的AR应用程序的基本构建块：一个AR浏览器（例如Junaio、Layar或Wikitude）。
- en: Knowing where you are – handling GPS
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 知道你的位置——处理GPS
- en: In this section, we will look at one of the major approaches for mobile AR and
    sensor-based AR (see [Chapter 1](ch01.html "Chapter 1. Augmented Reality Concepts
    and Tools"), *Augmented Reality Concepts and Tools*), which uses **global tracking**.
    Global tracking refers to tracking in a global reference frame (world coordinate
    system), which can encompass the whole earth. We will first look at the position
    aspect, and then the location sensor built on your phone that will be used for
    AR. We will learn how to retrieve information from it using the Android API and
    will integrate its position information into JME.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨移动AR和基于传感器的AR（见[第1章](ch01.html "第1章. 增强现实概念和工具")，*增强现实概念和工具*）的一种主要方法，该方法使用**全局追踪**。全局追踪指的是在全球参考框架（世界坐标系）中的追踪，可以涵盖整个地球。我们首先会看看位置方面，然后是手机上用于AR的位置传感器。我们将学习如何使用Android
    API从中获取信息，并将其位置信息整合到JME中。
- en: GPS and GNSS
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPS和GNSS
- en: So we need to track the position of the user to know where he/she is located
    in the real world. While we say we track the user, handheld AR applications actually
    track the position of the device.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们需要追踪用户的位置，以了解他在现实世界中的位置。当我们说追踪用户时，手持AR应用程序实际上追踪的是设备的位置。
- en: Note
  id: totrans-7
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**User tracking versus device tracking**'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**用户追踪与设备追踪**'
- en: To create a fully-immersive AR application, you ideally need to know where the
    device is, where the body of the user in reference to the device is, and where
    the eyes of the user in reference of the body are. This approach has been explored
    in the past, especially with Head Mounted Displays. For that, you need to track
    the head of the user, the body of the user, and have all the static transformations
    between them (calibration). With mobile AR, we are still far from that; maybe
    in the future, users will wear glasses or clothes equipped with sensors which
    will allow creating more precise registration and tracking.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个完全沉浸式的AR应用程序，理想情况下，您需要知道设备的位置，用户相对于设备的位置，以及用户眼睛相对于身体的位置。这种方法在过去已经被探索过，尤其是在头戴式显示器中。为此，您需要追踪用户头部、身体，并拥有它们之间的所有静态变换（校准）。在移动AR中，我们离这还很远；也许将来，用户会佩戴或穿着配备传感器的眼镜或衣物，这将允许创建更精确的注册和追踪。
- en: 'So how do we track the position of the device in a global coordinate system?
    Certainly you, or maybe some of your friends, have used a GPS for car navigation
    or for going running or hiking. GPS is one example of a common technology used
    for global tracking, in reference to an earth coordinate system, as shown in the
    following figure:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们如何在一个全球坐标系统中追踪设备的位置呢？你或者你的朋友们肯定使用过GPS进行汽车导航、跑步或远足。GPS是一种用于全球追踪的常见技术，参照地球坐标系统，如下面的图所示：
- en: '![GPS and GNSS](img/8553_04_01.jpg)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![GPS和GNSS](img/8553_04_01.jpg)'
- en: Most mobile phones are now equipped with GPS, so it seems an ideal technology
    for global tracking in AR. A GPS is the American version of a **global navigation
    satellite system** (**GNSS**). The technology relies on a constellation of geo-referenced
    satellites, which can give your position anywhere around the planet using geographic
    coordinates. GPS is not the only GNSS out there; a Russian version (**GLONASS**)
    is currently also operational, and a European version (**Galileo**) will be effective
    around 2020\. However, GPS is currently the most supported GNSS on mobile devices,
    so we will use this term for the rest of the book when we talk about tracking
    with GNSS.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 现在大多数手机都配备了GPS，因此它似乎成为AR中全球追踪的理想技术。GPS是美国版的**全球导航卫星系统**（**GNSS**）。这项技术依赖于一系列地理参考卫星，它们可以使用地理坐标在全球任何地方给出你的位置。GPS并不是唯一的GNSS，一个俄罗斯版本（**GLONASS**）目前也在运行中，而一个欧洲版本（**Galileo**）将在2020年左右生效。然而，GPS是目前在移动设备上支持最广泛的GNSS，因此在本书的其余部分，当我们讨论使用GNSS进行追踪时，我们将使用这个术语。
- en: 'For common AR applications relying on GPS, you have two things to consider:
    the digital content location and the device location. If both of them are defined
    in the same coordinate system, in reference to earth, you will be able to know
    how they are in reference to each other (see the elliptical pattern in the following
    figure). With that knowledge, you can model the position of the 3D content in
    the user coordinate system and update it with each location update from your GPS
    sensor. As a result, if you move closer to an object (bottom to top), the object
    will appear closer (and bigger in the image), reproducing the behavior you have
    in the normal world.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 对于依赖GPS的常见AR应用，你需要考虑两件事：数字内容的位置和设备的位置。如果它们都在参照地球的同一坐标系统中定义，你将能够了解它们相对于彼此的位置（见下面图中的椭圆形图案）。有了这些知识，你可以在用户坐标系统中建模3D内容的位置，并通过GPS传感器的每次位置更新来更新它。因此，如果你向一个物体移动（从下到上），物体将显得更近（在图像中也更大），复现你在现实世界中的行为。
- en: '![GPS and GNSS](img/8553_04_02.jpg)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![GPS和GNSS](img/8553_04_02.jpg)'
- en: A small issue we have with this technology is related to the coordinate system
    used in GPS. Using latitude and longitude coordinates (what a basic GPS delivers)
    is not the most adapted representation for using AR. When we do 3D graphics, we
    are used to a Euclidian coordinate system to position digital content; position
    using the Cartesian coordinate system, defined in terms of X, Y, and Z coordinates.
    So we need to address this problem by transforming these GPS coordinates to something
    more adapted.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在使用这项技术时遇到的一个小问题是与GPS使用的坐标系统有关。使用纬度和经度坐标（基本GPS提供的数据）并不是使用AR的最适应表示。当我们进行3D图形处理时，我们习惯于使用欧几里得坐标系统来定位数字内容；使用笛卡尔坐标系统来定义位置，即X、Y和Z坐标。因此，我们需要通过将这些GPS坐标转换成更适应的形式来解决这一问题。
- en: JME and GPS – tracking the location of your device
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: JME和GPS——追踪你的设备位置
- en: The Google Android API offers access to GPS through the Location Manager service.
    The Location Manager can provide you GPS data, but it can also use the network
    (for example, Wi-Fi and cellphone network) to pinpoint your location and give
    you a rough estimation of it. In Android terminology, this is named Location Provider.
    To use the Location Manager, you need to apply the standard Android mechanism
    for notifications in Android based on a listener class; `LocationListener` in
    this case.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 谷歌的Android API通过位置管理器服务提供了对GPS的访问。位置管理器可以提供你GPS数据，但它也可以使用网络（例如Wi-Fi和手机网络）来精确你的位置，并给出一个大致的估计。在Android术语中，这被称为位置提供者。要使用位置管理器，你需要应用基于监听器类的Android通知的标准Android机制；在这种情况下是`LocationListener`。
- en: So open the `LocationAccessJME` project associated with this chapter, which
    is a modified version of the `SuperimposeJME` project ([Chapter 3](ch03.html "Chapter 3. Superimposing
    the World"), *Superimposing the World*).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 所以打开与本章关联的`LocationAccessJME`项目，这是`SuperimposeJME`项目（[第3章](ch03.html "第3章. 覆盖世界")，*覆盖世界*）的修改版本。
- en: 'First, we need to modify our Android manifest to allow access to the GPS sensor.
    They are different quality modes regarding GPS (quality of estimated location),
    we will authorize all of them. So add these two permissions to your `AndroidManifest.xml`
    file:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要修改Android清单，以允许访问GPS传感器。关于GPS有不同的质量模式（估计位置的质量），我们将授权所有这些模式。因此，请将这两个权限添加到您的`AndroidManifest.xml`文件中：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The project has, same as before, a JME class (`LocationAccessJME`), an activity
    class (`LocationAccessJMEActivity`), as well as `CameraPreview`. What we need
    to do is create a `LocationListener` class and a `LocationManager` class that
    we add to our `LocationAccessJMEActivity` class:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 该项目与之前一样，有一个JME类（`LocationAccessJME`），一个活动类（`LocationAccessJMEActivity`），以及`CameraPreview`。我们需要做的是创建一个`LocationListener`类和一个`LocationManager`类，并将它们添加到我们的`LocationAccessJMEActivity`类中：
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Inside the `LocationListener` class, we need to override different callback
    functions:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在`LocationListener`类中，我们需要重写不同的回调函数：
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The `onLocationChanged` callback is the one which is the call for any changes
    in a user''s location; the location parameter contains both the measured latitude
    and longitude (in degrees). To pass the converted data to our JME, we will use
    the same principle as before: call a method in our JME class using the location
    as argument. So `setUserLocation` will be called each time there is an update
    of the location of the user, and the new value will be available to the JME class.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '`onLocationChanged`回调是当用户位置发生变化时的调用；位置参数包含测量的纬度和经度（以度为单位）。为了将转换后的数据传递给我们的JME，我们将使用与前一个相同的原则：使用位置作为参数调用JME类中的方法。因此，每次用户位置更新时都会调用`setUserLocation`，新的值将对JME类可用。'
- en: 'Next, we need to access the location manager service and register our location
    listener to it, using the `requestLocationUpdates` function:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要访问定位管理服务，并使用`requestLocationUpdates`函数向其注册我们的位置监听器：
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The parameters of `requestLocationUpdates` are the types of provider we want
    to use (GPS versus network), update frequency (in milliseconds), and change of
    position threshold (in meters) as our listener.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '`requestLocationUpdates`方法的参数包括我们想要使用的定位提供者类型（GPS或网络），更新频率（以毫秒为单位），以及作为我们监听器的位置变化阈值（以米为单位）。'
- en: 'On the JME side, we need to define two new variables to our `LocationAccessJME`
    class:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在JME方面，我们需要为我们的`LocationAccessJME`类定义两个新变量：
- en: '[PRE4]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We also need to define our `setUserLocation` function, which is called from
    the callback in `LocationListener`:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要定义我们的`setUserLocation`函数，该函数从`LocationListener`中的回调中被调用：
- en: '[PRE5]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Inside this function we need to transform the position of the camera from latitude/longitude
    format to a Cartesian coordinate system. There are different techniques to do
    so; we will use the conversion algorithm from the SatSleuth website ([http://www.satsleuth.com/GPS_ECEF_Datum_transformation.htm](http://www.satsleuth.com/GPS_ECEF_Datum_transformation.htm)),
    converting our data to an **ECEF** (**Earth-Centered, Earth-Fixed**) format. Now
    we have `mUserPosition` available in ECEF format in our JME class. Each time a
    user's location will change, the `onLocationChange` method and `setUserLocation`
    will be called and we will get an updated value of `mUserPosition`. The question
    now is how we use this variable in our scenegraph and in relation with geo-referenced
    digital content (for example, POI)?
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个函数中，我们需要将摄像头的位置从纬度/经度格式转换成笛卡尔坐标系。实现这一转换有不同的技术；我们将使用SatSleuth网站上的转换算法（[http://www.satsleuth.com/GPS_ECEF_Datum_transformation.htm](http://www.satsleuth.com/GPS_ECEF_Datum_transformation.htm)），将我们的数据转换为**ECEF**（**地球中心，地球固定**）格式。现在我们的JME类中有了以ECEF格式可用的`mUserPosition`。每次用户位置发生变化时，都会调用`onLocationChange`方法和`setUserLocation`，我们将得到`mUserPosition`的更新值。现在的问题是我们如何将这个变量用于我们的场景图并与地理参考数字内容（例如，POI）相关联？
- en: 'The method to use is to reference your content locally from your current position.
    For doing that, we need to use an additional coordinate system: the **ENU** (**East-North-Up**)
    coordinate system. For each data you have (for example, a certain number of POIs
    at 5 km radius from your position), you compute the location from your current
    position. Let''s have a look at how we can do that on our ninja model, as shown
    in the following code:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 使用的办法是从您的当前位置本地引用内容。为此，我们需要使用一个附加的坐标系：**东-北-上（ENU）**坐标系。对于您拥有的每个数据（例如，从您位置出发5公里半径内的若干个兴趣点），您需要从当前的位置计算其位置。下面让我们看看如何对我们的忍者模型进行这样的操作，如下面的代码所示：
- en: '[PRE6]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The position of the ninja in latitude-longitude format (`locationNinja`) is
    also converted to the ECEF format (`ECEFNinja`). From there, using the current
    GPS location (in latitude-longitude format and ECEF format, location, mUserPosition),
    we compute the position of the ninja in a local coordinate system (`ENUNinja`).
    Each time the user moves, his or her GPS position will be updated, transformed
    to ECEF format, and the local position of the content will be updated, which will
    trigger a different rendering. That''s it! We have implemented GPS-based tracking.
    An illustration of the relation of the different coordinate systems is represented
    in the following figure:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 忍者位置的纬度-经度格式（`locationNinja`）也被转换成地心地固坐标系（`ECEFNinja`）格式。从那里，使用当前的GPS位置（以纬度-经度格式和地心地固坐标系格式，即位置`mUserPosition`），我们计算忍者在本地方坐标系（`ENUNinja`）中的位置。每次用户移动时，他的GPS位置将被更新，转换为地心地固坐标系格式，并且将更新内容的本地位置，这将触发不同的渲染。就是这样！我们已经实现了基于GPS的追踪。不同坐标系之间的关系说明如图所示：
- en: '![JME and GPS – tracking the location of your device](img/8553_04_03.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![JME和GPS——追踪您设备的位置](img/8553_04_03.jpg)'
- en: 'The only remaining part is to update the position of the model using the new
    local position. We can implement that from the `simpleUpdate` function by adding
    the following code:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的唯一部分就是使用新的本地位置来更新模型的位置。我们可以通过在`simpleUpdate`函数中添加以下代码来实现这一点：
- en: '[PRE7]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: In a real AR application, you may have some 3D content positioned around your
    current position in a GPS coordinate system, such as having a virtual ninja positioned
    in Fifth street in New York, or in front of the Eiffel Tower in Paris.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个真正的AR应用中，您可能会在GPS坐标系中以您当前位置为中心放置一些3D内容，例如在纽约第五街放置一个虚拟的忍者，或者在巴黎的埃菲尔铁塔前。
- en: 'Since we want to be sure, you can run this sample independently of where you
    are currently testing and reading the book (from New York to Timbuktu). We will
    modify this demo slightly for educational purposes. What we will do is add the
    ninja model at 10 meters from your initial GPS location (that is, first time the
    GPS updates), by adding the following call in `setUserLocation`:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们希望确保无论您在何处进行测试和阅读本书（从纽约到廷巴克图），都可以独立运行这个示例。出于教育目的，我们将稍微修改这个演示。我们将要做的是在`setUserLocation`中添加以下调用，在您的初始GPS位置10米处添加忍者模型（即第一次GPS更新时）：
- en: '[PRE8]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Time for testing: deploy the application on your mobile and go outside to a
    location where you should get a nice GPS reception (you should be able to see
    the sky and avoid a really cloudy day). Don''t forget to activate the GPS on your
    device. Start the application, move around and you should see the ninja shifting
    positions. Congratulations, you developed your first instance of tracking for
    an AR application!'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 测试时间：将应用程序部署到您的移动设备上，并前往一个可以获得良好GPS信号的位置（您应该能够看到天空，并避免在非常多云的日子进行测试）。不要忘记在设备上激活GPS。启动应用程序，四处移动，您应该能看到忍者位置的变化。恭喜您，您已经开发出了您的第一个增强现实（AR）应用的追踪实例！
- en: Knowing where you look – handling inertial sensors
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 了解您的注视方向——处理惯性传感器
- en: With the previous example and access to GPS location, we can now update a user's
    location and be able to do a basic tracking in Augmented Reality. However, this
    tracking is only considering position of the user and not his or her orientation.
    If, for example, the user rotates the phone, nothing will happen, with changes
    being effective only if he is moving. For that we need to be able to detect changes
    in rotation for the user; this is where inertial sensors come in. The inertial
    sensors can be used to detect changes in orientation.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 通过前面的示例和访问GPS位置，我们现在可以更新用户的位置，并能够在增强现实中进行基本的追踪。然而，这种追踪只考虑了用户的位置，而没有考虑他的方向。例如，如果用户旋转手机，将不会发生任何变化，只有在他移动时变化才有效。为此，我们需要能够检测用户方向的变化；这时就需要用到惯性传感器。惯性传感器可以用来检测方向的变化。
- en: Understanding sensors
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解传感器
- en: 'In the current generation of mobile phones, three types of sensors are available
    and useful for orientation:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在当前一代的手机中，有三种类型的传感器可用于定位：
- en: '**Accelerometers**: These sensors detect the proper acceleration of your phone,
    also called **g-force** acceleration. Your phone is generally equipped with multi-axis
    model to deliver you acceleration in the 3 axes: pitch, roll, and tilt of your
    phone. They were the first sensors made available on mobile phones and are used
    for sensor-based games, being cheap to produce. With accelerometers, and a bit
    of elementary physics, you are able to compute the orientation of the phone. They
    are, however, rather inaccurate and the measured data is really noisy (which can
    result in getting jitters in your AR application).'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**加速度计**：这些传感器检测手机的正加速度，也称为**g力**加速度。手机通常配备有多轴模型，可以提供三个轴上的加速度：手机的俯仰、翻滚和倾斜。它们是手机上最早使用的传感器，用于基于传感器的游戏，生产成本低廉。通过加速度计和一点基础物理知识，你可以计算出手机的方向。然而，它们相当不准确，测量数据非常嘈杂（可能导致你的AR应用出现抖动）。'
- en: '**Magnetometers**: They can detect the earth''s magnetic field and act like
    a compass. Ideally, you can get the north direction with them by measuring the
    magnetic field in three dimensions and know where your phone points. The challenge
    with magnetometers is that they can easily be distracted by metallic objects around
    them, such as a watch on the user''s wrist, and then indicate a wrong north direction.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**磁力计**：它们可以检测地球的磁场，就像指南针一样。理想情况下，你可以通过测量三维磁场来获取北方方向，从而知道手机指向哪里。磁力计的挑战在于，它们很容易受到周围金属物体的影响，比如用户手腕上的手表，进而指示出错误的北方方向。'
- en: '**Gyroscopes**: They measure angular velocity using the **Coriolis Effect**.
    The ones used in your phone are **multi-axis miniature mechanical system** (**MEMS**)
    using a vibrating mechanism. They are more accurate than the previous sensors,
    but their main issue is the drift: the accuracy of measurement decreases over
    time; after a short period your measure starts getting really inaccurate.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**陀螺仪**：它们通过**科里奥利效应**测量角速度。手机中使用的是**多轴微型机械系统**（**MEMS**），采用振动机制。它们比之前的传感器更准确，但主要问题是漂移：测量精度随时间降低；短时间后，测量开始变得非常不准确。'
- en: You can combine measurements of each of them to address their limitations, as
    we will see later in this chapter. Inertial sensors have been used intensively
    before coming to mobile phones, the most famous usage being in planes for measuring
    their orientation or velocity, used as an **inertial measurement unit** (**IMU**).
    As manufacturers always try to cut down costs, quality of the sensors varies considerably
    between mobile devices. The effect of noise, drift, and inaccuracy will induce
    your AR content to jump or move without you displacing the phone or it may lead
    to positioning the content in the wrong orientation. Be sure you test a range
    of them if you want to deploy your application commercially.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将它们的测量值结合起来，以解决它们的局限性，我们将在本章后面看到。在手机使用之前，惯性传感器已经被广泛使用，最著名的应用是在飞机上测量其方向或速度，用作**惯性测量单元**（**IMU**）。由于制造商总是试图降低成本，不同移动设备之间的传感器质量差异很大。噪声、漂移和不准确的影响将导致你的AR内容在你没有移动手机的情况下跳跃或移动，或者可能导致内容定位在错误的方向。如果你想要商业部署你的应用，确保你测试了它们的一系列性能。
- en: Sensors in JME
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: JME中的传感器
- en: 'Sensor access on Google Android API is made through `SensorManager`, and uses
    `SensorListener` to retrieve measurements. `SensorManager` doesn''t give you access
    only to the inertial sensors, but to all the sensors present on your phone. Sensors
    are divided in three categories in the Android API: motion sensors, environmental
    sensors, and position sensors. The accelerometers and the gyroscope are defined
    as motion sensors; the magnetometer is defined as a position sensor. The Android
    API also implements some software sensors, which combine the values of these different
    sensors (which may include position sensor too) to provide you with motion and
    orientation information. The five motion sensors available are:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在Google Android API中，通过`SensorManager`访问传感器，并使用`SensorListener`获取测量值。`SensorManager`不仅提供对惯性传感器的访问，还提供对所有手机上传感器的访问。在Android
    API中，传感器分为三类：运动传感器、环境传感器和位置传感器。加速度计和陀螺仪被定义为运动传感器；磁力计被定义为位置传感器。Android API还实现了一些软件传感器，这些传感器结合了这些不同传感器的值（可能包括位置传感器）来提供运动和方向信息。可用的五个运动传感器包括：
- en: '`TYPE_ACCELEROMETER`'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TYPE_ACCELEROMETER`'
- en: '`TYPE_GRAVITY`'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TYPE_GRAVITY`'
- en: '`TYPE_GYROSCOPE`'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TYPE_GYROSCOPE`'
- en: '`TYPE_LINEAR_ACCELERATION`'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TYPE_LINEAR_ACCELERATION`'
- en: '`TYPE_ROTATION_VECTOR`'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TYPE_ROTATION_VECTOR`'
- en: 'Please refer to the Google Developer Android website [http://developer.android.com/guide/topics/sensors/sensors_overview.html](http://developer.android.com/guide/topics/sensors/sensors_overview.html),
    for more information about the characteristics of each of them. So let''s open
    the `SensorAccessJME` project. As we did before, we define a `SensorManager` class
    and we will add a `Sensor` class for each of these motion sensors:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考谷歌开发者安卓网站[http://developer.android.com/guide/topics/sensors/sensors_overview.html](http://developer.android.com/guide/topics/sensors/sensors_overview.html)，了解更多关于它们各自特性的信息。现在让我们打开`SensorAccessJME`项目。像之前一样，我们定义了一个`SensorManager`类，并为每个这些运动传感器添加一个`Sensor`类：
- en: '[PRE9]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We also need to define `SensorListener`, which will handle any sensor changes
    from the motion sensors:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要定义`SensorListener`，它将处理来自运动传感器的任何传感器变化：
- en: '[PRE10]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Note
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意事项
- en: The rotation changes could also solely be handled with Quaternions, but we explicitly
    used Euler angles for a more intuitive understanding. Privilege quaternions as
    composing rotations is easier and they don't suffer from "gimbal lock".
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 旋转变化也可以仅使用四元数来处理，但我们明确使用欧拉角以便更直观地理解。优先使用四元数，因为它们组合旋转更容易，并且不会出现“万向节死锁”。
- en: 'Our listener overrides two callbacks: the `onAccuracyChanged` and `onSensorChanged`
    callbacks. The `onSensorChanged` channel will be called for any changes in the
    sensors we registered to `SensorManager`. Here we identify which type of sensor
    changed by querying the type of event with `event.sensor.getType()`. For each
    type of sensor, you can use the generated measurement to compute the new orientation
    of the device. In this example we will only show you how to use the value of the
    `TYPE_ROTATION_VECTOR` sensor (software sensor). The orientation delivered by
    this sensor needs to be mapped to match the coordinate frame of the virtual camera.
    We pass Euler angles (heading, pitch, and roll) to the JME application to achieve
    this in the JME application''s `setRotation` function (the Euler angle is just
    another representation of orientation and can be calculated from Quaternions and
    axis-angle representations delivered in the sensor event).'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的监听器重写了两个回调：`onAccuracyChanged`和`onSensorChanged`。当我们注册到`SensorManager`的传感器有任何变化时，将调用`onSensorChanged`通道。这里我们通过查询`event.sensor.getType()`来确定是哪种类型的传感器发生了变化。对于每种类型的传感器，你可以使用生成的测量值来计算设备的新方向。在这个例子中，我们只向你展示如何使用`TYPE_ROTATION_VECTOR`传感器的值（软件传感器）。这个传感器提供的方向需要映射到与虚拟相机坐标帧相匹配。我们将欧拉角（偏航，俯仰和翻滚）传递给JME应用程序，在JME应用程序的`setRotation`函数中实现这一点（欧拉角只是方向的另一种表示，可以从传感器事件中提供的四元数和轴角表示计算得出）。
- en: 'Now, having our `SensorListener`, we need to query `SensorManager` to get the
    sensor service and initialize our sensors. In your `onCreate` method add:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，有了我们的`SensorListener`，我们需要查询`SensorManager`以获取传感器服务并初始化我们的传感器。在你的`onCreate`方法中添加：
- en: '[PRE11]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'After getting access to the sensor service, we query the list of all available
    sensors and display the results on our logcat. For initializing the sensors, we
    call our `initSensors` method, and define it as:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在获取传感器服务访问权限后，我们查询所有可用传感器的列表，并在我们的logcat上显示结果。为了初始化传感器，我们调用我们的`initSensors`方法，并定义如下：
- en: '[PRE12]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The function `initSingleSensor` will create an instance of `Sensor` and register
    our previously created listener with a specific type of sensor passed in argument:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '`initSingleSensor`函数将创建一个`Sensor`实例，并注册我们之前创建的监听器，传递特定类型的传感器参数：'
- en: '[PRE13]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We shouldn''t forget to unregister the listener when we quit the application,
    so modify your `onStop` method as follows:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们退出应用程序时，我们不应该忘记注销监听器，因此按照以下方式修改你的`onStop`方法：
- en: '[PRE14]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'So, we are now set in our `Activity`. In our `SensorAccessJME` class we add
    following variables:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们现在在`Activity`中设置好了。在我们的`SensorAccessJME`类中，我们添加以下变量：
- en: '[PRE15]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The variable `mInitialCamRotation` holds the initial camera orientation, `mRotXYZQ`
    holds the sensor orientation mapped to the camera coordinate system, and `mCurrentCamRotation`
    stores the final camera rotation which is composed from multiplying `mInitialCamRotation`
    with `mRotXYZQ`. The `setRotation` function takes the sensor values from the Android
    activity and maps them to the camera coordinate system. Finally, it multiplies
    the current rotation values with the initial camera orientation:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 变量`mInitialCamRotation`保存初始摄像头方向，`mRotXYZQ`保存映射到摄像头坐标系的传感器方向，`mCurrentCamRotation`存储最终摄像头旋转，它是由`mInitialCamRotation`与`mRotXYZQ`相乘得到的。`setRotation`函数从Android活动中获取传感器值并将它们映射到摄像头坐标系。最后，它将当前旋转值与初始摄像头方向相乘。
- en: '[PRE16]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'As a last step, we need to use this rotation value for our virtual camera,
    the same as we did for our GPS example. In `simpleUpdate` you now add:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最后一步，我们需要将这个旋转值用于我们的虚拟摄像头，就像我们在GPS示例中所做的那样。在`simpleUpdate`中，你现在需要添加：
- en: '[PRE17]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'So, we are now ready to run the application. It''s important to consider that
    the natural orientation of the device, which defines the coordinate system for
    motion sensors, is not the same for all devices. If your device is, by default,
    in the portrait mode and you change it to landscape mode , the coordinate system
    will be rotated. In our examples we explicitly set the device orientation to landscape.
    Deploy your application on your device using this default orientation mode. You
    may need to rotate your device around to see the ninja moving on your screen,
    as shown in the following screenshots:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们准备运行应用程序。重要的是要考虑设备的自然方向，它定义了运动传感器的坐标系，并不是所有设备都相同。如果你的设备默认是纵向模式，而你将其改为横向模式，坐标系将会旋转。在我们的示例中，我们明确将设备方向设置为横向。使用此默认方向模式将你的应用程序部署到设备上。你可能需要旋转设备，以便在屏幕上看到忍者的移动，如下面的截图所示：
- en: '![Sensors in JME](img/8553_04_04.jpg)![Sensors in JME](img/8553_04_05.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![JME中的传感器](img/8553_04_04.jpg)![JME中的传感器](img/8553_04_05.jpg)'
- en: Improving orientation tracking – handling sensor fusion
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 改进方向追踪——处理传感器融合
- en: One of the limitations with sensor-based tracking is the sensors. As we introduced
    before, some of the sensors are inaccurate, noisy, or have drift. A technique
    to compensate their individual issue is to combine their values to improve the
    overall rotation you can get with them. This technique is called sensor fusion.
    There are different methods for fusing the sensors, we will use the method presented
    by *Paul Lawitzki* with a source code under MIT License available at [http://www.thousand-thoughts.com/2012/03/android-sensor-fusion-tutorial/](http://www.thousand-thoughts.com/2012/03/android-sensor-fusion-tutorial/).
    In this section, we will briefly explain how the technique works and how to integrate
    sensor fusion to our JME AR application.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 基于传感器的追踪的一个限制是传感器本身。正如我们之前所介绍的，一些传感器不准确、有噪声或存在漂移。一种补偿它们各自问题的技术是将它们的值结合起来，以提高你可以获得的整体旋转。这种技术称为传感器融合。融合传感器有不同的方法，我们将使用*Paul
    Lawitzki*提出的方法，并提供一个在MIT许可下的源代码，可访问[http://www.thousand-thoughts.com/2012/03/android-sensor-fusion-tutorial/](http://www.thousand-thoughts.com/2012/03/android-sensor-fusion-tutorial/)。在本节中，我们将简要解释这项技术是如何工作的，以及如何将传感器融合集成到我们的JME
    AR应用程序中。
- en: Sensor fusion in a nutshell
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 传感器融合简述
- en: 'The fusion algorithm proposed by *Paul Lawitzki* merges accelerometers, magnetometers,
    and gyroscope sensor data. Similar to what is done with software sensor of an
    Android API, accelerometers and magnetometers are first merged to get an absolute
    orientation (magnetometer, acting as a compass, gives you the true north). To
    compensate for the noise and inaccuracy of both of them, the gyroscope is used.
    The gyroscope, being precise but drifting over time, is used at high frequency
    in the system; the accelerometers and magnetometers are considered over longer
    periods. Here is an overview of the algorithm:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '*Paul Lawitzki*提出的融合算法将加速度计、磁力计和陀螺仪传感器数据融合在一起。类似于Android API中的软件传感器处理方式，首先将加速度计和磁力计融合在一起，以获得绝对方向（磁力计作为指南针，为你提供真正的北方向）。为了补偿两者的噪声和不准确，使用陀螺仪。陀螺仪精确但随时间漂移，在系统中以高频率使用；加速度计和磁力计则考虑更长的周期。以下是算法的概述：'
- en: '![Sensor fusion in a nutshell](img/8553_04_06.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![传感器融合简述](img/8553_04_06.jpg)'
- en: You can find more information about the details of the algorithm (complimentary
    filter) on *Paul Lawitzki's* webpage.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在*Paul Lawitzki*的网页上找到更多关于算法（补充滤波器）细节的信息。
- en: Sensor fusion in JME
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: JME中的传感器融合
- en: 'Open the `SensorFusionJME` project. The sensor fusion uses a certain number
    of internal variables that you declare at the beginning of `SensorFusionJMEActivity`:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 打开`SensorFusionJME`项目。传感器融合使用了一定数量的内部变量，你在`SensorFusionJMEActivity`的开始部分声明这些变量。
- en: '[PRE18]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Also add the code of different subroutines used by the algorithm:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 还要添加算法使用的不同子程序的代码：
- en: '`calculateAccMagOrientation`: Calculates the orientation angles from the accelerometer
    and magnetometer measurement'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`calculateAccMagOrientation`：从加速度计和磁力计的测量值计算方向角度'
- en: '`getRotationVectorFromGyro`: Calculates a rotation vector from the gyroscope
    angular speed measurement'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`getRotationVectorFromGyro`：从陀螺仪角速度测量计算旋转矢量'
- en: '`gyroFunction`: Writes the gyroscope-based orientation into `gyroOrientation`'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gyroFunction`：将基于陀螺仪的方向写入`gyroOrientation`'
- en: '**Two matrix transformation functions**: `getRotationMatrixFromOrientation`
    and `matrixMultiplication`'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**两个矩阵变换函数**：`getRotationMatrixFromOrientation`和`matrixMultiplication`'
- en: 'The main part of the processing is done in the `calculatedFusedOrientationTask`
    function. This function generates new fused orientation as part of `TimerTask`,
    a task that can be scheduled at a specific time. At the end of this function,
    we will pass the generated data to our JME class:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 处理的主要部分在`calculatedFusedOrientationTask`函数中完成。这个函数作为`TimerTask`的一部分生成新的融合方向，`TimerTask`是一个可以在特定时间安排的任务。在这个函数的末尾，我们将生成的数据传递给我们的JME类：
- en: '[PRE19]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The argument passed to our JME activity bridge function (`setRotationFused`)
    is the fused orientation defined in the Euler angles format.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 传递给我们的JME活动桥接函数（`setRotationFused`）的参数是在欧拉角格式中定义的融合方向。
- en: 'We also need to modify our `onSensorChanged` callback to call the subroutines
    used by `calculatedFusedOrientationTask`:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要修改我们的`onSensorChanged`回调，以调用`calculatedFusedOrientationTask`使用的子程序：
- en: '[PRE20]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'For our activity class, the last change is to specify a task for our timer,
    specify the schedule rate, and the delay before the first execution. We add that
    to our `onCreate` method after the call to `initSensors`:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的活动类，最后的更改是指定一个定时器的任务，指定计划速率以及首次执行前的延迟。我们在调用`initSensors`之后，在`onCreate`方法中添加这个：
- en: '[PRE21]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'On the JME side, we define a new bridge function for updating the rotation
    (and again converting the sensor orientation into an appropriate orientation of
    the virtual camera):'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在JME方面，我们定义了一个新的桥接函数用于更新旋转（再次将传感器方向转换为虚拟相机的适当方向）：
- en: '[PRE22]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: We finally use this function in the same way as for `setRotation` in `simpleUpdate`,
    updating camera orientation with `fgCam.setAxes(mCurrentCamRotationFused)`. You
    can now deploy the application and see the results on your device.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们在`simpleUpdate`中与`setRotation`一样使用这个函数，通过`fgCam.setAxes(mCurrentCamRotationFused)`更新相机方向。你现在可以部署应用程序并在你的设备上查看结果。
- en: If you combine the `LocationAccessJME` and `SensorAccessJME` examples, you will
    now get full 6 degrees of freedom (6DOF) tracking, which is the foundation for
    a classical sensor-based AR application.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你将`LocationAccessJME`和`SensorAccessJME`示例结合起来，你现在将获得完整的6自由度（6DOF）跟踪，这是基于经典传感器增强现实应用的基础。
- en: Getting content for your AR browser – the Google Places API
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为你的增强现实浏览器获取内容——使用Google Places API
- en: 'After knowing how to obtain your GPS position and the orientation of the phone,
    you are now ready to integrate great content into the live view of the camera.
    Would it not be cool to physically explore points of interests, such as landmarks
    and shops around you? We will now show you how to integrate popular location-based
    services such as the Google Places API to achieve exactly this. For a successful
    integration into your application, you will need to perform the following steps:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在知道如何获取你的GPS位置和手机的方向之后，你现在可以准备将优秀的内容集成到相机的实时视图中。如果能够物理探索你周围的兴趣点，如地标和商店，岂不是很酷？现在我们将向你展示如何集成流行的基于位置的服务，如Google
    Places API，以实现这一点。为了成功集成到你的应用程序中，你需要执行以下步骤：
- en: Query for point of interests (POIs) around your current location
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查询你当前位置周围的兴趣点（POIs）
- en: Parse the results and extract information belonging to the POIs
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解析结果并提取属于POIs的信息。
- en: Visualize the information in your AR view
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在你的增强现实视图中可视化信息
- en: Before we start, you have to make sure that you have a valid API key for your
    application. For that you also need a Google account. You can obtain it by logging
    in with your Google account under [https://code.google.com/apis/console](https://code.google.com/apis/console).
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，你必须确保你的应用程序有一个有效的API密钥。为此，你需要一个Google账户。你可以通过使用你的Google账户登录[https://code.google.com/apis/console](https://code.google.com/apis/console)来获取。
- en: 'For testing your application you can either use the default project `API Project`
    or create a new one. To create a new API key you need to:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试你的应用程序，你可以使用默认项目`API Project`，或者创建一个新的。要创建新的API密钥，你需要：
- en: Click on the link **Services** in the menu on the left-hand side.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击左侧菜单中的**服务**链接。
- en: Activate the Places API status switch.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 激活Places API状态开关。
- en: Access your key by clicking on the **API access** menu entry on the left-hand
    side menu and looking at the **Simple API Access** area.
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过点击左侧菜单中的**API访问**菜单项，并查看**简单API访问**区域来获取你的密钥。
- en: You can store the key in the `String mPlacesKey = "<YOUR API KEY HERE>"` variable
    in the `LocationAccessJME` project.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在`LocationAccessJME`项目中将密钥存储在`String mPlacesKey = "<YOUR API KEY HERE>"`变量中。
- en: Next, we will show you how to query for POIs around the devices location, and
    getting some basic information such as their name and position. The integration
    of this information into the AR view follows the same principles as described
    in the *JME and GPS – tracking the location of your device* section.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将向你展示如何查询设备位置周围的POI，并获得一些基本信息，例如它们的名称和位置。将这些信息集成到AR视图中的原则与*JME和GPS——追踪你的设备位置*一节中描述的原则相同。
- en: Querying for POIs around your current location
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查询你当前位置周围的POI
- en: Previously in this chapter, you learned how to obtain your current location
    in the world (latitude and longitude). You can now use this information to obtain
    the location of POIs around you. The Google Places API allows you to query for
    landmarks and businesses in the vicinity of the user via HTTP requests and returns
    the results as JSON or XML strings. All queries will be addressed towards URLs
    starting with [https://maps.googleapis.com/maps/api/place/](https://maps.googleapis.com/maps/api/place/).
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章前面，你已经学习了如何获取你在世界上的当前位置（纬度和经度）。你现在可以使用这些信息来获取你周围的POI位置。Google Places API允许你通过HTTP请求查询用户周边的地标和商家，并以JSON或XML字符串的形式返回结果。所有查询都将指向以[https://maps.googleapis.com/maps/api/place/](https://maps.googleapis.com/maps/api/place/)开头的URL。
- en: While you could easily make the queries in your web browser, you would want
    to have both the request sent and the response processed inside your Android application.
    As calling a URL and waiting for the response can take up several seconds, you
    would want to implement this request-response processing in a way that does not
    block the execution of your main program. Here we show you how to do that with
    threads.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管你可以在网页浏览器中轻松地进行查询，但你会希望在你的Android应用程序内部发送请求并处理响应。由于调用URL并等待响应可能需要花费数秒钟，因此你需要以不阻塞主程序执行的方式来实现这种请求-响应处理。下面我们将展示如何使用线程来实现这一点。
- en: 'In your `LocationAccessJME` project, you define some new member variables,
    which take care of the interaction with the Google Places API. Specifically, you
    create a `HttpClient` for sending your request and a list `List<POI> mPOIs`, for
    storing the most important information about POIs. The `POI` class is a simple
    helper class to store the Google Places reference string (a unique identifier
    in the Google Places database, the POI name, its latitude, and longitude):'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的`LocationAccessJME`项目中，你定义了一些新的成员变量，它们负责与Google Places API的交互。具体来说，你创建了一个`HttpClient`来发送请求，以及一个`List<POI>
    mPOIs`列表，用于存储关于POIs的最重要信息。`POI`类是一个简单的帮助类，用于存储Google Places引用字符串（在Google Places数据库中的唯一标识符，POI名称，纬度和经度）：
- en: '[PRE23]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Of course, you can easily extend this class to hold additional information such
    as street address or image URLs. To query for POIs you make a call to the `sendPlacesQuery`
    function. We do the call at program startup, but you can easily do it in regular
    intervals (for example, when the user moves a certain distance) or explicitly
    on a button click.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，你可以轻松地扩展这个类以保存其他信息，例如街道地址或图片URL。为了查询POI，你调用了`sendPlacesQuery`函数。我们在程序启动时进行调用，但你可以很容易地在固定时间间隔内进行（例如，当用户移动一定距离时）或明确地在按钮点击时进行。
- en: '[PRE24]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: In this method, we create a new thread for each query to the Google Places service.
    This is very important for not blocking the execution of the main program. The
    response of the Places API should be a JSON string, which we pass to a `Handler`
    instance in the main thread to parse the JSON results, which we will discuss next.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在此方法中，我们为每次对Google Places服务的查询创建一个新线程。这对于不阻塞主程序的执行非常重要。Places API的响应应该是一个JSON字符串，我们将它传递给主线程中的`Handler`实例来解析JSON结果，接下来我们将讨论这一点。
- en: Parsing the Google Places APIs results
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解析Google Places API的结果
- en: Google Places returns its result in the lightweight JSON format (with XML being
    another option). You can use the `org.json` library delivered as a standard Android
    package to conveniently parse those results.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: Google Places以轻量级的JSON格式（XML是另一种选择）返回结果。您可以使用作为标准Android包提供的`org.json`库方便地解析这些结果。
- en: 'A typical JSON result for your query will look like:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 您查询的典型JSON结果将如下所示：
- en: '[PRE25]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'In `handleMessage` of our handler `placesPOIQueryHandler`, we will parse this
    JSON string into a list of POIs, which then can be visualized in your AR view:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的处理程序`placesPOIQueryHandler`的`handleMessage`中，我们将解析这个JSON字符串到一个POI列表，然后可以在您的AR视图中进行可视化：
- en: '[PRE26]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: So that is it. You now have your basic POI information and with the latitude,
    longitude information you can easily instantiate new 3D objects in JME and position
    them correctly relative to your camera position, just as you did with the ninja.
    You can also query for more details about the POIs or filter them by various criteria.
    For more information on the Google Places API please visit [https://developers.google.com/places/documentation/](https://developers.google.com/places/documentation/).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样。现在您已经有了基本的POI信息，并且有了纬度和经度信息，您可以在JME中轻松实例化新的3D对象，并将它们相对于相机位置正确地定位，就像您对忍者所做的那样。您还可以查询有关POI的更多详细信息，或者根据各种标准对它们进行过滤。有关Google
    Places API的更多信息，请访问[https://developers.google.com/places/documentation/](https://developers.google.com/places/documentation/)。
- en: Tip
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: If you want to include text in the 3D scene, we recommend avoiding the use of
    3D text objects as they result in a high number of additional polygons to render.
    Use bitmap text instead, which you render as a texture on a mesh that can be generated.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想在3D场景中包含文本，我们建议避免使用3D文本对象，因为它们会导致需要渲染的额外多边形数量增多。您可以使用位图文本替代，将其渲染为可以在网格上生成的纹理。
- en: Summary
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this chapter we introduced you to the first popular methods of mobile AR:
    GPS and sensor-based Augmented Reality. We introduced the basic building blocks
    of tracking the device location in a global reference frame, dynamically determining
    the device orientation, improving the robustness of orientation tracking, and
    finally using the popular Google Places API to retrieve information about POIs
    around the user which can then be integrated into the AR view.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们向您介绍了移动AR的第一种流行方法：基于GPS和传感器的增强现实。我们介绍了跟踪设备在全球参考框架中的位置的基本构建块，动态确定设备方向，提高方向跟踪的鲁棒性，并最终使用流行的Google
    Places API获取关于用户周围POI的信息，然后可以将这些信息集成到AR视图中。
- en: 'In the next chapter we will introduce you to the second popular way of realizing
    mobile AR: computer vision-based Augmented Reality.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将向您介绍实现移动AR的第二种流行方式：基于计算机视觉的增强现实。
