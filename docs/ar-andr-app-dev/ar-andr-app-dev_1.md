# 第一章. 增强现实概念与工具

**增强现实**（**AR**）为我们提供了一种与物理（或真实）世界互动的新方式。它在我们桌面电脑或移动设备的屏幕上，创建了一个融入了数字（或虚拟）信息的现实世界的改良版本。将虚拟与现实融合在一起可以开创一系列全新的用户体验，超越常见应用的能力范围。你能想象在自家附近玩第一人称射击游戏，街角突然冒出怪物吗（正如澳大利亚南澳大学的*Bruce Thomas*开发的 ARQuake 中所示，见下截图左侧）？在自然历史博物馆看到尘封的恐龙骨架在你眼前虚拟复活，血肉丰满，难道不是一件激动人心的事情吗？或者，当你给孩子讲故事时，看到一只骄傲的公鸡出现在书上并走在页面之上（正如*Gavin Bishop*所著的《杰克建的房子》AR 版所示，见下截图右侧）。在这本书中，我们将向您展示如何在 Android 平台上实际实现这些体验。

![增强现实概念与工具](img/8553_01_01.jpg)

十年前，有经验的研发人员是少数能够创建这类应用程序的人群。它们通常仅限于演示原型或者在有限时间内运行的临时项目中。现在，开发增强现实（AR）体验已经成为广泛移动软件开发者的现实。在过去的几年里，我们见证了计算能力、传感器小型化以及多媒体库的易用性和功能性的巨大进步。这些进展使得开发者能够比以往更容易地制作 AR 应用程序。这已经导致在诸如 Google Play 之类的移动应用商店中涌现出越来越多的 AR 应用。尽管热情的程序员可以轻松地将一些基本的代码片段拼凑起来，创建一个基本 AR 应用的外观，但它们通常设计粗糙，功能有限，几乎不具备可重用性。为了能够创建复杂的 AR 应用，我们必须真正理解增强现实（Augmented Reality）是什么。

在本章中，我们将引导您更深入地理解 AR。我们将描述 AR 的一些主要概念。然后，我们将从这些例子过渡到 AR 的基础软件组件。最后，我们将介绍本书将使用的开发工具，这些工具将支持我们构建高效且模块化的 AR 软件架构的旅程。

准备好为了增强现实而改变你的现实了吗？让我们开始吧。

# AR 概念快速概览

随着近年来增强现实在媒体上变得越来越流行，不幸的是，一些关于增强现实的扭曲观念也产生了。任何与真实世界有关，并涉及一些计算的活动，比如站在商店前观看 3D 模型穿着最新时尚，都变成了增强现实。增强现实从几十年前的实验室研究中出现，产生了不同的定义。随着越来越多研究领域（例如，计算机视觉、计算机图形学、人机交互、医学、人文和艺术）将增强现实作为一个技术、应用或概念进行研究，现在存在多个重叠的增强现实定义。我们不会为您提供详尽的定义列表，而是介绍任何增强现实应用中存在的一些主要概念。

## 感官增强

“增强现实”这个词本身包含了现实的概念。增强通常指的是通过附加信息影响你的一个人类感官系统，如视觉或听觉的方面。这种信息通常被定义为数字或虚拟的，并由计算机生成。目前的技术使用**显示**来叠加和融合物理信息与数字信息。为了增强你的听觉，配备麦克风的改良耳机或耳塞能够实时将你周围的声音与计算机生成的声音混合。在这本书中，我们将主要关注视觉增强。

### 显示技术

家中的电视屏幕是感知虚拟内容的理想设备，无论是来自广播的流媒体还是播放的 DVD 内容。不幸的是，大多数常见的电视屏幕无法捕捉现实世界并将其增强。增强现实显示需要同时展示真实世界和虚拟世界。

增强现实最早期的显示技术之一是由*Ivan Sutherland*在 1964 年生产的（名为“达摩克利斯之剑”）。该系统被刚性安装在天花板上，并使用一些 CRT 屏幕和一个透明显示来创建视觉上融合真实和虚拟的感觉。

从那时起，我们在增强现实显示中看到了不同的趋势，从静态显示发展到可穿戴和手持显示。其中一个主要趋势是使用**光学透视**（**OST**）技术。这个想法是仍然通过半透明屏幕看到真实世界，并在屏幕上投射一些虚拟内容。真实世界和虚拟世界的融合不是在电脑屏幕上发生的，而是直接在你的视网膜上，如下面的图所示：

![显示技术](img/8553_01_03.jpg)

AR 显示的另一个主要趋势是我们所说的**视频透视**（**VST**）技术。你可以想象不是直接感知世界，而是通过显示器上的视频来感知。视频图像与一些虚拟内容混合（正如你在电影中看到的）并返回到一些标准显示设备，如桌面屏幕、移动电话或如下图中即将出现的一代头戴式显示器：

![显示设备](img/8553_01_04.jpg)

在本书中，我们将使用安卓驱动的移动电话，因此只讨论 VST 系统；所使用的摄像机将是手机背面的那一个。

### 3D 注册

手持显示设备（OST 或 VST），你已经能够将真实世界中的事物叠加在上面，正如你在电视广告中看到屏幕底部有文字横幅。然而，任何虚拟内容（如文本或图像）将保持其在屏幕上的固定位置。这种叠加实际上是静态的，你的 AR 显示屏将充当**抬头显示**（**HUD**），但并不是如下图所示的那种真正的 AR：

![3D 注册](img/8553_01_05.jpg)

Google Glass 是一个 HUD 的例子。尽管它使用像 OST 那样的半透明屏幕，但数字内容保持在一个静态位置。

增强现实（AR）需要更多地了解真实内容和虚拟内容。它需要知道物体在空间中的位置（**注册**）并跟踪它们的移动（**追踪**）。

注册基本上是将虚拟和真实内容在同一空间对齐的想法。如果你喜欢看电影或体育，你会注意到 2D 或 3D 图形经常被叠加到物理世界的场景中。在冰球中，球通常用彩色轨迹突出显示。在诸如*沃尔特·迪士尼*的《创》（1982 年版）等电影中，真实和虚拟元素无缝融合。然而，AR 与这些效果不同，因为它基于以下所有方面（由*Ronald T. Azuma*在 1997 年提出）：

+   **它是 3D 的**：在早期，有些电影是通过手动编辑将虚拟视觉效果与真实内容合并的。一个著名的例子是《星球大战》，其中所有的光剑效果都是由数百名艺术家手工绘制的，因此是逐帧制作的。如今，更复杂的技术支持将数字 3D 内容（如角色或汽车）与视频图像合并（这称为匹配移动）。AR 本质上始终在 3D 空间中完成这一工作。

+   **注册是实时发生的**：在电影中，一切都是预先录制并在工作室中生成的；你只需播放媒体。在 AR 中，一切都是实时的，因此你的应用程序需要在每个实例中将现实与虚拟性合并。

+   **它是交互式的**：在电影中，你只是被动地从拍摄场景的地方观看。在 AR 中，你可以主动地四处移动，前进和后退，并转动你的 AR 显示屏——你仍然会看到两个世界之间的对齐。

### 与环境的互动

构建丰富的 AR 应用需要环境之间的交互；否则，你最终会得到很快就变得无聊的漂亮 3D 图形。AR 交互是指选择和操作数字和物理对象，并在增强的场景中导航。丰富的 AR 应用允许你使用桌面上的对象，移动一些虚拟角色，在街上行走时用手选择一些漂浮的虚拟对象，或者与出现在你的手表上的虚拟代理交谈，安排当天晚些时候的会议。在第六章 *让它互动——创造用户体验*中，我们将讨论移动 AR 的交互。我们将探讨一些标准的移动交互技术如何也应用于 AR。我们还将深入研究涉及操作现实世界的特定技术。

## 选择你的风格——基于传感器和计算机视觉的增强现实（AR）

在本章前面的内容中，我们讨论了增强现实（AR）的定义，并详细阐述了显示、注册和交互。由于本书中的一些概念同样适用于任何 AR 开发，我们将特别关注**移动 AR**。

移动 AR 有时指的是任何可携带、可穿戴的 AR 系统，这种系统可以在室内外使用。在本书中，我们将探讨目前最流行的移动 AR 含义——使用手持移动设备，如智能手机或平板电脑。借助当前一代的智能手机，可以实现两种主要的 AR 系统方法。这些系统以其特定的注册技术和交互范围为特征，同时它们也支持不同范围的应用。基于传感器的 AR 和基于计算机视觉的 AR 系统都使用视频透视显示，依赖于手机的摄像头和屏幕。

### 基于传感器的 AR

第一类系统称为基于传感器的 AR，通常被称为 GPS 加惯性 AR（有时也称为户外 AR 系统）。基于传感器的 AR 使用移动设备的位置传感器和方向传感器。结合位置和方向传感器可以提供用户在物理世界中的全球位置。

位置传感器主要支持**全球导航卫星系统**（**GNSS**）接收器。最流行的 GNSS 接收器之一是 GPS（由美国维护），它几乎存在于所有智能手机上。

### 注意事项

其他系统目前正在（或即将）部署，例如 GLONASS（俄罗斯）、Galileo（欧洲，2020 年）或 Compass（中国，2020 年）。

手持设备上有几种可能的定向传感器，如加速度计、磁力计和陀螺仪。你的手持设备测量的位置和方向提供了追踪信息，这些信息用于在物理场景上注册虚拟对象。由 GPS 模块报告的位置可能不准确，且更新速度比你移动的速度慢。这可能导致**滞后**现象，即当你快速移动时，虚拟元素似乎会飘在后面。基于传感器的系统中最受欢迎的 AR 应用类型之一是 AR 浏览器，它们可以可视化**兴趣点**（**POI**），即关于你周围事物的简单图形信息。如果你尝试一些最受欢迎的产品，如 Junaio、Layar 或 Wikitude，你可能会观察到这种滞后效应。

这种技术的优点在于，基于传感器的增强现实（AR）可以在全球范围内普遍适用，几乎在任何物理户外位置都能工作（比如你身处于沙漠中央或是一座城市中）。这种系统的一个限制是它们无法在室内工作（或者工作效果差），或者在任意遮挡区域工作（与天空没有视线，如在森林中或四周高楼林立的街道上）。我们将在第四章《在世界中定位》中进一步讨论这种类型的移动 AR 系统。

### 基于计算机视觉的 AR

另一种流行的 AR 系统是基于计算机视觉的 AR。这里的想法是利用内置相机的力量，不仅仅是为了捕捉和显示物理世界（如基于传感器的 AR 所做的）。这项技术通常与图像处理和计算机视觉算法一起工作，分析图像以检测相机可见的任何物体。这种分析可以提供关于不同物体位置的信息，因此也能提供关于用户的信息（更多内容请见第五章，《好莱坞风格——虚拟物体叠加在物理物体上》）。

这种技术的优点是事物似乎完美对齐。当前技术允许你识别不同类型的平面图像内容，比如特别设计的标记（**基于标记的追踪**）或更自然的内容（**无标记追踪**）。一个缺点是，基于视觉的 AR 在处理上较为繁重，并且可能非常快地耗尽电池。最近几代的智能手机更适合处理这类问题，因为它们针对能源消耗进行了优化。

## 增强现实（AR）架构概念

因此，让我们探讨如何支持之前描述的概念以及两种通用 AR 系统的发展。与开发任何其他应用程序一样，一些软件工程中的知名概念可以应用于 AR 应用程序的开发。我们将先看看 AR 应用程序的结构方面（软件组件），然后是行为方面（控制流程）。

### AR 软件组件

增强现实应用程序可以结构化为三层：应用层、AR 层和操作系统/第三方层。

**应用层**对应于应用程序的领域逻辑。如果您想开发一个 AR 游戏，与游戏资源管理（角色、场景、物体）或游戏逻辑相关的任何内容都将在这个特定层中实现。AR 层对应于我们之前描述的概念的实例化。我们之前提出的每个 AR 概念和理念（显示、注册和交互）在软件层面都可以被视为一个模块元素、组件或 AR 层的服务。

你可以注意到，在图中我们将跟踪与注册分离开了，使得跟踪成为 AR 应用程序的一个主要软件组件。在任何 AR 应用程序中，提供空间信息给注册服务的跟踪都是一个复杂且计算密集型的过程。操作系统/第三方层对应于现有的工具和库，它们本身不提供任何 AR 功能，但将支持 AR 层。例如，移动应用程序的**显示**模块将与操作系统层通信，访问摄像头以创建物理世界的视图。在 Android 上，Google Android API 就是这一层的一部分。一些额外的库，如处理图形的 JMonkeyEngine，也是这一层的一部分。

在本书的其余部分，我们将向您展示如何实现 AR 层的不同模块，这也涉及到与操作系统/第三方层的通信。AR 应用程序的主要层（见以下图的右侧），以及它们的应用模块（以下图的左侧），在以下图中描绘：

![AR 软件组件](img/8553_01_06.jpg)

### AR 控制流程

在了解了软件层次和组件的概念之后，我们现在可以看看在典型的增强现实（AR）应用程序中信息的流动方式。在这里，我们将重点描述 AR 层的每个组件随时间如何相互关联，以及它们与操作系统/第三方层之间的连接是什么。

在过去十年中，AR 研究人员和开发人员趋向于使用一种广泛采用的方法来组合这些组件，并采用类似的执行顺序——AR 控制流程。在这里，我们介绍了社区总结并在以下图中概述的一般 AR 控制流程：

![AR 控制流程](img/8553_01_07.jpg)

前面的图表，从下往上阅读，展示了 AR 应用程序的主要活动。这个顺序在 AR 应用程序中无限重复；它可以被视为典型的**AR 主循环**（请注意，我们在这里排除了领域逻辑以及操作系统活动）。每个活动对应我们之前展示的相同模块。因此，AR 层和 AR 控制流程的结构非常对称。

了解这个控制流程是开发 AR 应用程序的关键，因此我们将在本书的剩余部分回到这个主题并使用它。下一章我们将详细讲解各个组件和步骤。

因此，查看前面的图表，你的应用程序中的主要活动和步骤如下：

+   **首先管理显示**：对于移动 AR 来说，这意味着访问视频摄像头并在屏幕上显示捕获的图像（你物理世界的视图）。我们将在第二章，*观察世界*中讨论这个问题。这也涉及到在物理摄像头和渲染你的数字对象的虚拟摄像头之间匹配相机参数（第三章，*覆盖世界*）。

+   **注册并跟踪你的对象**：分析你手机上的传感器（方法 1）或分析视频图像（方法 2），并检测你的世界中的每个元素的位置（如相机或物体）。我们将在第四章，*在世界中定位*和第五章，*与好莱坞相同 - 在物理对象上的虚拟*中讨论这个方面。

+   **互动**：一旦你的内容正确注册，你就可以开始与它互动，我们将在第六章，*让它互动 - 创建用户体验*中讨论这一点。

## 开发和部署的系统要求

如果你想要为 Android 开发增强现实应用程序，你可以与常规 Android 开发者共享大部分工具。特别是，你可以利用广泛支持的**谷歌 Android 开发者工具包**（**ADT Bundle**）。它包括以下内容：

+   Eclipse **集成开发环境**（**IDE**）

+   用于 Eclipse 的**谷歌 Android 开发者工具**（**ADT**）插件

+   针对你的目标设备的 Android 平台（可以下载其他平台）

+   带有最新系统映像的 Android 模拟器

除了这个许多 Android 开发环境共有的标准包之外，你还需要以下内容：

+   **JMonkeyEngine**（**JME**）的快照，版本 3 或更高

+   **高通® Vuforia^(TM)** **软件开发包**（**Vuforia^(TM)**），版本 2.6 或更高

+   **Android 原生开发工具包**（**Android NDK**），版本 r9 或更高

JME Java OpenGL®游戏引擎是一个免费的工具集，可以让你的程序中的 3D 图形生动起来。它提供了 3D 图形和游戏中间件，使你无需专门使用低级**OpenGL**® **ES** (**OpenGL® for Embedded Systems**，例如)进行编码，通过提供导入模型的资源系统、预定义的照明、物理和特效组件。

高通® Vuforia^(TM) SDK 集成了先进的计算机视觉算法，旨在识别和跟踪各种对象，包括校准标记（框架标记）、图像目标和甚至 3D 对象。虽然它对于基于传感器的 AR 不是必需的，但它可以让你方便地实现基于计算机视觉的 AR 应用程序。

谷歌 Android NDK 是用于性能关键型应用程序的工具集。它允许应用程序的部分内容用本地代码语言（C/C++）编写。虽然你不需要用 C 或 C++编码，但 Vuforia^(TM) SDK 需要这个工具集。

当然，你不必局限于特定的 IDE，也可以使用命令行工具。我们在这本书中提供的代码片段并不依赖于特定 IDE 的使用。然而，在本书中，我们将为你提供针对流行的 Eclipse IDE 的设置说明。此外，所有开发工具都可以在 Windows（XP 或更高版本）、Linux 和 Mac OS X（10.7 或更高版本）上使用。

在接下来的页面中，我们将指导你完成 Android 开发者工具包、NDK、JME 和 Vuforia^(TM) SDK 的安装过程。虽然开发工具可以分散在系统中，但我们建议你为开发工具和示例代码使用一个共同的基目录；我们称之为`AR4Android`（例如，在 Windows 下的`C:/AR4Android`或在 Linux 或 Mac OS X 下的`/opt/AR4Android`）。

### 安装 Android 开发者工具包和 Android NDK

你可以通过以下两个简单步骤安装 ADT Bundle：

1.  从[`developer.android.com/sdk/index.html`](http://developer.android.com/sdk/index.html)下载 ADT Bundle。

1.  下载后，将`adt-bundle-<os_platform>.zip`解压到`AR4Android`基础目录。

然后，你可以通过启动`AR4Android/adt-bundle-<os_platform>/eclipse/eclipse(.exe)`来启动 Eclipse IDE。

### 提示

请注意，根据你使用的设备，你可能需要安装额外的系统映像（例如，版本 2.3.5 或 4.0.1）。你可以按照以下网站的说明操作：[`developer.android.com/tools/help/sdk-manager.html`](http://developer.android.com/tools/help/sdk-manager.html)。

对于 Android NDK（版本 r9 或更高），你可以按照以下类似的步骤操作：

1.  从[`developer.android.com/tools/sdk/ndk/index.html`](http://developer.android.com/tools/sdk/ndk/index.html)下载。

1.  下载后，将`android-ndk-r<version>Y-<os_platform>.(zip|bz2)`解压到`AR4Android`基础目录。

### 安装 JMonkeyEngine

JME 是一个基于 Java 的强大 3D 游戏引擎。它自带开发环境（基于 NetBeans 的 JME IDE），主要针对桌面游戏的开发。尽管 JME IDE 也支持部署到 Android 设备，但在本书撰写之时，它还没有集成像 ADT Bundle 中那样的便捷 Android SDK 工具，例如**Android 调试桥**（**adb**）、**Dalvik 调试监控服务器视图**（**DDMS**）或 Android 模拟器的集成。因此，我们将不使用 JME IDE，而是将基本库集成到我们在 Eclipse 中的 AR 项目中。获取 JME 库的最简单方法是，从 [`jmonkeyengine.org/downloads`](http://jmonkeyengine.org/downloads) 下载适用于你操作系统的 SDK 并安装到 `AR4Android` 基础目录（或你自己的开发者目录；只要确保稍后在你的项目中能轻松访问即可）。在本书出版之时，有三个软件包：Windows、GNU/Linux 和 Mac OS X。

### 提示

你也可以从 [`updates.jmonkeyengine.org/nightly/3.0/engine/`](http://updates.jmonkeyengine.org/nightly/3.0/engine/) 获取最新版本。

对于使用 ADT Bundle 进行 AR 开发，你只需要 JME 的 Java 库（`.jar`）。如果你在 Windows 或 Linux 上工作，可以通过执行以下步骤将它们包含在任何现有的 Eclipse 项目中：

1.  在 Eclipse 资源管理器中右键点击你的 AR 项目（我们将在下一章创建）或其他任何项目，然后选择**构建路径** | **添加外部存档**。

1.  在**JAR 选择**对话框中，浏览至 `AR4Android/jmonkeyplatform/jmonkeyplatform/libs` 目录。

1.  你可以选中 lib 目录中的**所有 JAR 文件**，然后点击**打开**。

如果你使用的是 Mac OS X，在应用与 Windows 或 Linux 前一节描述的相同步骤之前，应该从 `jmonkeyplatform.app` 中提取库。要提取库，你需要右键点击 `jmonkeyplatform.app` 应用并选择**显示包内容**，你会在 `/Applications/jmonkeyplatform.app/Contents/Resources/` 找到库。

请注意，在本书的背景下，我们只使用其中的一部分。在随书附带的 Eclipse 项目中，你会发现必要的 JAR 文件已经位于本地 lib 目录中，其中包含了运行示例所需的 Java 库子集。你还可以在构建路径中引用它们。

### 注意

使用 JME 与 Android 相关的参考文档可以在 [`hub.jmonkeyengine.org/wiki/doku.php/jme3:android`](http://hub.jmonkeyengine.org/wiki/doku.php/jme3:android) 找到。

### 安装 Vuforia^(TM)

Vuforia^(TM) 是一个最先进的计算机视觉识别和自然特征跟踪库。

为了下载和安装 Vuforia^(TM)，你首先需要在[`developer.vuforia.com/user/register`](https://developer.vuforia.com/user/register)进行注册。注册后，你可以从[`developer.vuforia.com/resources/sdk/android`](https://developer.vuforia.com/resources/sdk/android)下载 SDK（支持 Windows、Linux 或 Mac OS X）。创建一个名为`AR4Android/ThirdParty`的文件夹。然后通过选择**文件** | **新建** | **项目 ...**，创建一个名为`ThirdParty`的 Eclipse 项目，并将位置选择为文件夹`AR4Android/ThirdParty`（也见第二章中的*创建 Eclipse 项目*一节，*观察世界*）。接着在`AR4Android/ThirdParty/vuforia-sdk-android-<VERSION>`安装 Vuforia^(TM) SDK。对于第五章，*好莱坞级——实物上的虚拟*和第六章，*互动体验——创建用户体验*中的示例，你需要引用这个`ThirdParty Eclipse`项目。

## 你应该使用哪些 Android 设备？

你将学习的增强现实应用程序将在各种 Android 智能手机和平板电脑上运行。然而，根据特定的算法，我们将引入一些硬件要求。具体来说，Android 设备需要具备以下特性：

+   用于本书所有示例的后置摄像头

+   用于基于传感器的 AR 示例的 GPS 模块

+   用于基于传感器的 AR 示例的陀螺仪或线性加速度计

在手机上实现增强现实可能会具有挑战性，因为许多集成传感器必须在应用程序运行期间保持活跃，并执行计算密集型算法。因此，我们建议在双核处理器（或多核）上部署以获得最佳的 AR 体验。最早应部署的 Android 版本应为 2.3.3（API 10，姜饼）。这使你的 AR 应用有可能覆盖大约 95%的所有 Android 设备。

### 注意事项

访问[`developer.android.com/about/dashboards/index.html`](http://developer.android.com/about/dashboards/index.html)获取最新的数据。

请确保按照[`developer.android.com/tools/device.html`](http://developer.android.com/tools/device.html)的描述为开发设置你的设备。

此外，大多数 AR 应用程序，尤其是基于计算机视觉的应用程序（使用 Vuforia^(TM)），需要足够的处理能力。

# 总结

在本章中，我们介绍了 AR 的基础背景。我们展示了 AR 的一些主要概念，如感官增强、专用的显示技术、物理和数字信息的实时空间注册以及与内容的互动。

我们还介绍了基于计算机视觉和传感器的增强现实（AR）系统，这是移动设备上架构的两个主要趋势。同时，我们还描述了一个 AR 应用程序的基本软件架构块，并将以此作为本书后续内容的指导。至此，你应该已经安装了接下来章节中将使用的第三方工具。在下一章中，你将开始学习如何查看虚拟世界并使用 JME 实现相机访问。
