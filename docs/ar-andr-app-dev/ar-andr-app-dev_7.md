# 第七章：进一步阅读与技巧

在最后一章中，我们将为您提供更多高级技巧以及相关链接，以帮助提升任何 AR 应用的开发。我们将介绍内容管理技巧，如多目标和云识别，以及高级交互技术。

# 管理你的内容

对于基于计算机视觉的 AR，我们向你展示了如何使用单一目标构建应用。然而，在某些情况下，你可能需要同时使用多个标记。想象一下增强一个房间，你需要在每面墙上至少有一个目标，或者你可能希望你的应用能够识别并增强数百个不同的产品包装。前者可以通过追踪具有公共坐标框架的多个目标来实现，后者可以通过使用云识别的力量来实现。我们将在以下各节简要讨论这两种情况。

## 多目标

**多目标**不仅仅是几个单独图像的集合。它们实现了一个单一且连贯的坐标系统，手持设备可以在其中被追踪。只要至少有一个目标可见，这就允许场景的持续增强。创建多目标的主要挑战在于定义公共坐标系统（只需做一次）以及在设备运行期间保持这些目标的相对位置。

要创建公共坐标系统，你必须指定所有图像目标相对于公共原点的平移和方向。Vuforia^(TM)为你提供了一个选项，即使不涉及指定整个目标变换的细节，也可以构建常用的多目标，如立方体或长方体。在 Vuforia^(TM)目标管理器中，你可以简单地为具有立方体（长度、高度和宽度相等）或长方体（长度、高度和宽度不同）的目标添加一个立方体，该目标的坐标原点在（不可见）长方体的中心。你需要做的就是指定一个扩展到三个扩展的长方体，并为你的目标的每一面添加单独的图像，如下图所示：

![多目标](img/8553OS_07_01.jpg)

如果你想要创建更复杂的多目标，例如，追踪整个房间，你必须采取略有不同的方法。首先，你需要在 Vuforia^(TM)目标管理器中的单个设备数据库内上传所有想要用于多目标的多张图片。之后，将设备数据库下载到你的开发机上，然后你可以修改下载的`<database>.xml`文件，以添加单个图像目标的名字以及它们相对于坐标原点的平移和方向。你可以在 Vuforia^(TM)知识库中找到示例 XML 文件，链接为[`developer.vuforia.com/resources/dev-guide/creating-multi-target-xml-file`](https://developer.vuforia.com/resources/dev-guide/creating-multi-target-xml-file)。

请注意，您的设备数据库中最多只能有 100 个目标，因此，您的多目标最多只能由这么多图像目标组成。还要注意，在运行时更改图像目标的位置（例如，打开产品包装）将阻碍对您的坐标系的一致跟踪，即，各个目标元素之间定义的空间关系将不再有效。这甚至可能导致跟踪完全失败。如果您想将单个移动元素作为应用程序的一部分使用，除了多目标之外，您还必须将它们定义为单独的图像目标。

## 云端识别

如前所述，在您的 Vuforia^(TM)应用程序中，同时只能使用多达 100 个图像。通过使用云数据库，可以克服这一限制。这里的基本思想是，您使用摄像头图像查询云服务，如果在云端识别到目标，则可以在本地设备上处理已识别目标的跟踪。这种方法的主要优点是，您可以识别多达一百万张图像，这对于大多数应用场景来说应该是足够的。然而，这种好处并非没有代价。由于识别过程在云端进行，您的客户端必须连接到互联网，响应时间可能需要几秒钟（通常大约两到三秒）。

与云端识别不同，存储在设备上的图像数据库通常只需要大约 60 到 100 毫秒。为了更容易上传大量图像以供云端识别，您甚至不需要使用 Vuforia^(TM)在线目标管理网站，而可以使用特定的 Web API——Vuforia^(TM) Web 服务 API，该 API 可以在以下 URL 找到：[`developer.vuforia.com/resources/dev-guide/managing-targets-cloud-database-using-developer-api`](https://developer.vuforia.com/resources/dev-guide/managing-targets-cloud-database-using-developer-api)。您可以通过访问[`developer.vuforia.com/resources/dev-guide/cloud-targets`](https://developer.vuforia.com/resources/dev-guide/cloud-targets)在 Vuforia^(TM)知识库中找到有关使用云端识别的更多信息。

# 提高识别和跟踪

如果您想创建自己的自然特征跟踪目标，重要的是要设计它们，以便 AR 系统能够很好地识别和跟踪。第五章《与好莱坞相同——虚拟物体上的物理对象》中的*了解自然特征跟踪目标*部分介绍了自然特征目标的基础。可良好追踪的目标的基本要求是它们具有大量的局部特征。但如果您的目标识别不佳怎么办？在一定程度上，您可以通过使用以下技巧来改善跟踪。

首先，你想要确保图像具有足够的局部对比度。在 GIMP 或 Photoshop 等任何照片编辑软件中查看目标灰度表示的直方图是判断目标整体对比度的一个好方法。你通常希望直方图分布广泛，而不是像下面图中那样只有少数尖峰：

![提高识别和追踪](img/8553OS_07_02.jpg)

要增加图像的局部对比度，你可以使用你选择的照片编辑器，并应用去锐化蒙版滤镜或清晰度滤镜，如在 Adobe Lightroom 中。

### 提示

为了避免在 Vuforia^(TM)目标创建过程中出现重采样伪影，请确保上传的单个图像具有精确的 320 像素图像宽度。这样可以避免因服务器端自动调整图像大小而导致的走样效果和局部特征数量减少。通过改善渲染效果，Vuforia^(TM)会将你的图像重新缩放到最长图像边最大为 320 像素。

在本书的示例应用中，我们使用了不同类型的 3D 模型，包括基本图元（如我们的彩色立方体或球体）或更高级的 3D 模型（如忍者模型）。对于所有这些模型，我们并没有真正考虑真实感，包括光线条件。任何桌面或移动 3D 应用程序都会考虑渲染看起来如何真实。这种真实感追求始终通过模型几何质量、外观定义（材质反射属性）以及它们如何与光线交互（着色和照明）来体现。

**真实感渲染**将展示诸如遮挡（某物的前后）阴影（来自光照）对一系列真实材质的支持（使用着色器技术开发）或更高级的属性，例如支持全局照明。

当你开发 AR 应用时，还应该考虑真实感渲染。然而，事情会有些复杂，因为在 AR 中，你不仅要考虑虚拟方面（例如，桌面 3D 游戏），还要考虑真实方面。在 AR 中支持真实感意味着你需要考虑**真实（R）环境和虚拟（V）环境**在渲染过程中如何交互，可以通过以下四种不同情况简化如下：

1.  V→V

1.  V→R

1.  R→V

1.  R→R

最简单的事情是支持 V→V，这意味着你可以在 3D 渲染引擎中启用任何高级渲染技术。对于基于计算机视觉的应用程序，这意味着目标上的所有东西看起来都是真实的。对于基于传感器的应用程序，这意味着你的虚拟对象在彼此之间看起来是真实的。

对于基于计算机视觉的应用程序，第二步是使用平面技术支持 V→R（虚拟到现实）。如果你有一个目标，可以创建一个半透明的版本并将其添加到你的虚拟场景中。如果你启用了阴影，那么看起来阴影会投射到你的目标上，从而创建一个简单的 V→R（虚拟到现实）的错觉。你可以参考以下论文，其中提供了一些解决此问题的技术方案：

+   请参考*Michael Haller*、*Stephan Drab*和*Werner Hartmann*所著的《一种用于增强现实应用的实时阴影方法。VRST 2003: 56-65》。

处理 R→V（现实到虚拟）要复杂一些，仍然是一个困难的研究课题。例如，支持虚拟对象由物理光源照明需要付出大量的努力。

相反，对于 R→V 来说，遮挡是容易实现的。如果例如一个物理对象（如一个**罐头**）放在你的虚拟对象前面，那么 R→V 情况下的遮挡就会发生。在标准 AR（增强现实）中，你总是将虚拟内容渲染在视频前面，所以即使你的**罐头**实际上在目标前面，它看起来也会在后面。

产生这种效果的一个简单技术有时被称为**幻影对象**。你需要创建一个物理对象的虚拟对应物，比如一个圆柱体来代表你的罐头。将这个虚拟对应物放置在与物理对象相同的位置，并进行**仅深度渲染**。仅深度渲染在许多库中都可以使用，它与颜色遮罩有关，当你渲染任何东西时，你可以决定要渲染哪个通道。通常，你有红色、绿色、蓝色和深度的组合。因此，你需要关闭前三个通道，只激活深度。它将渲染一种幻影对象（没有颜色，只有深度），通过标准的渲染管线，在你有真实对象的地方，视频将不再被遮挡，遮挡看起来会非常真实；例如，请参阅[`hal.inria.fr/docs/00/53/75/15/PDF/occlusionCollaborative.pdf`](http://hal.inria.fr/docs/00/53/75/15/PDF/occlusionCollaborative.pdf)。

这是一种简单的情况；当你有一个动态对象时，事情要复杂得多，你需要能够跟踪你的对象，更新它们的幻影模型，并获得逼真的渲染效果。

# 高级交互技术

在前一章中，我们研究了一些简单的交互技术，包括光线选择（通过触摸交互）、传感器交互，或者摄像头与目标的接近性。在增强现实中，还有大量其他的交互技术可以使用。

我们在其他移动用户界面也会发现的一种标准技术是**虚拟控制面板**。由于移动电话限制了访问额外的控制设备，比如游戏手柄或操纵杆，你可以通过触摸界面模拟它们的行为。使用这项技术，你可以在屏幕上显示一个虚拟控制器，并将这一区域的触摸分析等同于控制一个控制面板。它易于实现并增强基本的射线投射技术。控制面板通常显示在屏幕边缘附近，适应形态因素，并捕捉到你持握设备时的手势，这样你可以用手握住设备，并在屏幕上自然地移动手指。

增强现实（AR）中另一种非常流行的技术是**有形用户界面**（**TUI**）。当我们使用摄像头对准近距离的概念来创建示例时，实际上我们实现了有形用户界面。TUI 的理念是使用物理对象来支持交互。这一概念主要由麻省理工学院的 Tangible Media Group 的*Iroshi Ishii*教授大力开发和丰富——相关网站可以参考[`tangible.media.mit.edu/`](http://tangible.media.mit.edu/)。*Mark Billinghurst*在他的博士研究中将这一概念应用于增强现实，并展示了一系列专用的交互技术。

TUI AR 的第一种类型是**本地交互**，例如，你可以使用两个目标进行交互。类似于我们在`ProximityBasedJME`项目中检测摄像头与目标之间的距离的方式，你可以用两个目标复制相同的想法。你可以检测两个目标是否彼此靠近，是否在同一方向上对齐，并触发一些动作。当你在卡片游戏中希望卡片之间进行交互，或者包含谜题的游戏需要用户组合不同的卡片时，你可以使用这种类型的交互。

第二种类型的 TUI AR 是**全局交互**，这种交互方式也需要使用两个或更多目标，但其中一个目标会变得*特殊*。在这种情况下，你需要定义一个目标作为基础目标，其他所有目标都参照这个基础目标。实现时，你只需计算其他目标相对于基础目标的局部变换，以基础目标作为原点并在其背后定义。这样，将目标放置在主目标上就变得非常简单，某种程度上定义了一个地面平面，并且可以与它进行一系列不同类型的交互。《Mark Billinghurst》介绍了一个著名的衍生版本，用于执行基于拨片的交互。在这种情况下，其中一个目标被用作拨片，可以用来在地面平面上进行交互——你可以触摸地面平面，让拨片在地面平面的特定位置，甚至用它来检测简单的手势（摇动拨片、倾斜拨片等）。为了设置移动 AR，你需要考虑到最终用户手持设备并不能执行复杂的手势，但使用手机时，单手交互仍然是可能的。参考以下技术论文：

+   *有形的增强现实。ACM SIGGRAPH ASIA（2008）：1-10*，作者*Mark Billinghurst*、*Hirokazu Kato*和*Ivan Poupyrev*。

+   *设计增强现实界面。ACM Siggraph Computer Graphics 39.1（2005）：17-22*，作者*Mark Billinghurst*、*Raphael Grasset*和*Julian Looser*。

从某种意义上说，与 TUI 的全局交互可以被定义为*屏幕背后*的交互，而虚拟控制面板可以被看作是*屏幕前方*的交互。这是与移动设备交互的另一种分类方式，它将我们引向了第三类交互技术：**目标上的触摸交互**。例如，Vuforia^(TM)库实现了虚拟按钮的概念。目标上的特定区域可以用来放置控制器（例如，按钮、滑块和旋钮），用户可以将手指放在这个区域上并控制这些元素。这个概念背后的原理是基于时间的；如果你将手指长时间放在这个区域，它会模拟你在电脑上可能进行的点击，或者在触摸屏上进行的轻敲。[例如，参考](https://developer.vuforia.com/resources/sample-apps/virtual-button-sample-app)。

研究实验室正在探索其他技术，这些技术很快就会成为未来移动增强现实（AR）的可用技术，因此在你考虑它们何时可用时，也应该将它们考虑在内。一个趋势是朝向 3D 手势交互，也被称为**空中交互**。你不再需要触摸屏幕或目标，可以想象在设备和目标之间进行手势操作。对于 3D 建模来说，移动 AR 将是一种适当的技巧。3D 手势面临许多挑战，比如识别手、手指、手势，以及可能导致疲劳的身体参与等等。在不久的将来，这种已经在智能家居设备（如微软的 Kinect）上普及的交互方式，将配备 3D 传感器的设备上得到应用。

# 总结

在本章中，我们向您展示了如何通过使用多目标或云识别来超越标准的 AR 应用，基于计算机视觉的 AR。我们还向您展示了如何提高图像目标的跟踪性能。此外，我们还向您介绍了一些用于 AR 应用的高级渲染技术。最后，我们还展示了一些新颖的交互技术，您可以使用它们来创造出色的 AR 体验。这一章为您介绍了 Android 增强现实开发世界的入门。我们希望您已经准备好进入 AR 应用开发的新层次。
