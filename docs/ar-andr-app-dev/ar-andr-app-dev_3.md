# 第三章. 叠加现实世界

现在你已经在屏幕上看到了物理世界的视图，我们下一个目标是在其上叠加数字 3D 模型。在增强现实中使用的 3D 叠加与使用 Adobe Photoshop 或类似绘图应用程序的基本 2D 叠加（我们仅调整两个 2D 图层的位置）不同。3D 叠加的概念涉及具有六个自由度（在三维度上进行平移和旋转）的内容管理和渲染，如下图所示：

![叠加现实世界](img/8553_03_01.jpg)

在本章中，我们将引导你了解不同的概念，并为你提供最佳的方式将真实和虚拟内容叠加。我们将依次介绍真实和虚拟相机的概念，如何使用我们的场景图引擎进行叠加，以及如何创建高质量的叠加。首先，让我们讨论 3D 世界和虚拟相机。

# 3D 渲染的构建块

表示和渲染虚拟 3D 内容的方式与你在物理世界中用数码相机拍照的方式相同。如果你给朋友或风景拍照，你首先会用肉眼检查你的拍摄对象，然后通过相机的取景器观察，最后才会拍照。这三种不同的步骤与虚拟 3D 内容相同。你没有用物理相机拍照，而是使用**虚拟相机**来渲染场景。你的虚拟相机可以看作是真实相机的数字表示，并且可以以类似的方式进行配置；你可以定位相机，改变其视野等。对于虚拟 3D 内容，你操作的是几何 3D 场景的数字表示，我们简单地称之为你的虚拟 3D 场景或虚拟世界。

使用 3D 计算机图形渲染场景的三个基本步骤如下所示，包括：

+   配置你的虚拟 3D 场景（对象的位置和外观）

+   配置你的虚拟相机

+   使用虚拟相机渲染 3D 场景

![3D 渲染的构建块](img/8553_03_02.jpg)

由于我们进行增强现实（AR）的实时渲染，你将需要循环执行这些步骤；在每一帧（通常为 20-30 FPS）都可以移动对象或相机。

在场景中定位物体或相机时，我们需要一种表示物体位置（以及方向）相对于彼此的方法。为此，我们通常使用基于几何数学模型的场景空间表示。最常见的方法是使用**欧几里得几何**和**坐标系**。一个坐标系定义了一种引用空间中物体（或点）的方法，使用数值表示来定义这个位置（**坐标**）。你的场景中的所有内容都可以在坐标系中定义，而坐标系之间可以通过**变换**相互关联。

以下是最常见的坐标系：

+   **世界坐标系**：这是你引用所有事物的地面。

+   **相机坐标系**：它放置在世界坐标系中，用于从这个特定的视角渲染你的场景。有时也被称为视点坐标系。

+   **局部坐标系**：例如，一个物体坐标系，用于表示一个物体的 3D 点。传统上，你可以使用物体的（几何）中心来定义你的局部坐标系。

![3D 渲染的构建块](img/8553_03_03.jpg)

### 提示

坐标系的方向有左右手两种约定：在两种约定中，X 轴都在右侧，Y 轴向上。在右手坐标系中，Z 轴指向你；而在左手坐标系中，Z 轴远离你。

另一个常见的坐标系在这里没有说明，是图像坐标系。如果你编辑图片，你可能对这个很熟悉。它定义了从参考原点（通常是图像的左上角或左下角）开始的每个像素的位置。当你进行 3D 图形渲染时，概念是相同的。现在我们将关注虚拟相机的特性。

# 实际相机与虚拟相机。

用于 3D 图形渲染的虚拟相机通常由两组主要参数表示：**外参**和**内参**。外参定义了相机在虚拟世界中的位置（从世界坐标系到相机坐标系的变换以及反之）。内参定义了相机的投影属性，包括其视场（焦距）、图像中心和倾斜。这两种参数可以用不同的数据结构表示，最常见的是矩阵。

如果您开发的是一款 3D 移动游戏，通常可以自由配置摄像头；您可以将摄像头放置在在地形上奔跑的 3D 角色上方（外置）或设置一个大的视场角以获得角色和地形的大范围视图（内置）。然而，当您进行增强现实（AR）时，选择会受到手机中真实摄像头属性的制约。在 AR 中，我们希望虚拟摄像头的属性与真实摄像头相匹配：视场角和摄像头位置。这是 AR 的一个重要元素，我们将在本章中进一步解释如何实现它。

## 摄像头参数（内在方向）

我们将在后续章节中探讨虚拟摄像头的 extrinsic 参数；它们用于增强现实中的 3D 注册。对于我们的 3D 叠加，我们现在将探讨摄像头的 intrinsic 参数。

有不同的计算模型可以表示虚拟摄像头（及其参数），我们将使用最流行的模型：针孔摄像头模型。针孔摄像头模型是对物理摄像头的简化模型，在这里您认为只有一个点（针孔）光线进入摄像头图像。有了这个假设，计算机视觉研究者简化了内在参数的描述如下：

+   **（物理或虚拟）镜头的焦距**：这和摄像头中心的尺寸一起决定了摄像头的**视场角**（**FOV**）——也称为视角。FOV 是摄像头可以看到的对象空间的范围，用弧度（或度）表示。它可以确定摄像头传感器的水平、垂直和斜向的视角。

+   **图像中心（主点）**：这适用于传感器从中心位置的任何位移。

+   **倾斜因子**：这用于非方形像素。

### 注意

在非移动摄像头中，您还应该考虑镜头畸变，比如径向畸变和切向畸变。它们可以通过先进的软件算法进行建模和校正。手机摄像头上的镜头畸变通常在硬件中进行校正。

有了这些概念，现在让我们进行一些实践操作。

# 使用场景图将 3D 模型叠加到摄像头视图中

在上一章中，你学习了如何设置单个视口和相机来渲染视频背景。虚拟相机决定了你的 3D 图形如何投射到 2D 图像平面上，而视口定义了将此图像平面映射到应用程序实际运行窗口的一部分（或智能手机的全屏，如果应用以全屏模式运行）。它决定了应用程序窗口中渲染图形的部分。多个视口可以堆叠并覆盖相同的或不同的屏幕区域，如下所示。对于基本的 AR 应用，你通常有两个视口。一个与渲染背景视频的相机相关联，另一个与渲染 3D 对象的相机一起使用。通常，这些视口覆盖整个屏幕。

![使用场景图将 3D 模型覆盖到相机视图上](img/8553_03_04.jpg)

视口大小不是以像素为单位定义的，而是无单位的，从 0 到 1 定义宽度和高度，以便能够轻松适应窗口大小的变化。一次只将一个相机关联到一个视口。

请记住，对于视频背景，我们使用了正交相机以避免视频图像的透视缩短。然而，这种透视对于正确视觉感受 3D 对象至关重要。正交（平行）投影（在以下图的左侧）和透视投影（在以下图的右侧）决定了如何将 3D 体积投射到 2D 图像平面上，如下所示：

![使用场景图将 3D 模型覆盖到相机视图上](img/8553_03_05a_FINAL.jpg)

JME 使用右手坐标系（OpenGL®约定，x 在右侧，y 向上，z 朝向你）。你当然希望随着相机靠近 3D 对象，它们看起来会更大，远离时则更小。那么我们该如何操作呢？没错，你只需添加第二个相机——这次是透视相机——以及一个关联的视口，这个视口也覆盖整个应用程序窗口。

在本章相关的`SuperimposeJME`项目中，我们同样拥有一个 Android 活动(`SuperimposeJMEActivity.java`)和一个 JME 应用程序类(`SuperimposeJME.java`)。应用程序无需对我们的上一个项目进行重大更改；你只需继承 JME 的`SimpleApplication`类即可。在其`simpleInitApp()`启动方法中，我们现在明确区分场景几何（视频背景：`initVideoBackground()`；3D 前景场景：`initForegroundScene()`）及其相关相机和视口的初始化：

```java
private float mForegroundCamFOVY = 30;
…
public void simpleInitApp() {
…
initVideoBackground(settings.getWidth(), settings.getHeight());
initForegroundScene();	
initBackgroundCamera();
initForegroundCamera(mForegroundCamFOVY);
…
}
```

请注意，初始化摄像头和视口（viewport）的顺序很重要。只有当我们首先添加视频背景的摄像头和视口（`initBackgroundCamera()`），然后添加前景摄像头和视口（`initForegroundCamera()`），才能确保我们的 3D 对象渲染在视频背景之上；否则，你只能看到视频背景。

现在，我们使用`initForegroundScene()`将你的第一个 3D 模型添加到场景中。JME 的一个便捷特性是它支持加载外部资源——例如 Wavefront 文件（`.obj`）或 Ogre3D 文件（`.mesh.xml`/`.scene`）——包括动画。我们将加载并动画化一个绿色忍者，这是 JME 自带的一个默认资源。

```java
private AnimControl mAniControl;
private AnimChannel mAniChannel;
…
public void initForegroundScene() {
Spatial ninja = assetManager.loadModel("Models/Ninja/Ninja.mesh.xml");
ninja.scale(0.025f, 0.025f, 0.025f);
ninja.rotate(0.0f, -3.0f, 0.0f);
ninja.setLocalTranslation(0.0f, -2.5f, 0.0f);
rootNode.attachChild(ninja);

DirectionalLight sun = new DirectionalLight();
sun.setDirection(new Vector3f(-0.1f, -0.7f, -1.0f));
rootNode.addLight(sun);

mAniControl = ninja.getControl(AnimControl.class);
mAniControl.addListener(this);
mAniChannel = mAniControl.createChannel();
mAniChannel.setAnim("Walk");
mAniChannel.setLoopMode(LoopMode.Loop);
mAniChannel.setSpeed(1f);
}
```

在这个方法中，你相对于项目的`root`/`asset`文件夹加载一个模型。如果你想加载其他模型，也请将它们放在这个`asset`文件夹中。你对模型进行缩放、平移和定位，然后将其添加到根场景图节点。为了使模型可见，你还需要添加一个从顶部前方照射到模型的方向光（你可以尝试不添加光看看结果）。对于动画，访问模型中存储的“Walk”动画序列。为此，你的类需要实现`AnimEventListener`接口，并使用`AnimControl`实例来访问该模型中的动画序列。最后，你将“Walk”序列分配给一个`AnimChannel`实例，告诉它循环动画，并设置动画速度。

很好，现在你已经加载了你的第一个 3D 模型，但你仍然需要在屏幕上显示它。

接下来在`initForegroundCamera(fovY)`中你会这样做。它负责为你的 3D 模型设置透视摄像头和相关视口。由于透视摄像头由其能看到的物体空间范围（即视场角 FOV）来定义，我们将存储在`mForegroundCamFOVY`中的垂直视角传递给该方法。然后它将包含 3D 模型的场景根节点附着到前景视口。

```java
public void initForegroundCamera(float fovY) {
  Camera fgCam = new Camera(settings.getWidth(), settings.getHeight());
  fgCam.setLocation(new Vector3f(0f, 0f, 10f));
  fgCam.setAxes(new Vector3f(-1f,0f,0f), new Vector3f(0f,1f,0f), new Vector3f(0f,0f,-1f));
  fgCam.setFrustumPerspective(fovY,  settings.getWidth()/settings.getHeight(), 1, 1000);

  ViewPort fgVP = renderManager.createMainView("ForegroundView", fgCam);
  fgVP.attachScene(rootNode);
  fgVP.setBackgroundColor(ColorRGBA.Blue);
  fgVP.setClearFlags(false, true, false);
}
```

尽管你可以直接复制一些默认摄像头的标准参数（类似于我们对视频背景摄像头所做的），但了解实际上需要执行哪些步骤来初始化新摄像头是很有好处的。在用窗口宽度和高度初始化透视摄像头后，你需要设置摄像头的位置（`setLocation()`）和旋转（`setAxes()`）。JME 使用右手坐标系，我们的摄像头配置为沿着负 z 轴看向原点，正如前一个图所示。此外，我们将传递给`setFrustumPerspective()`的垂直视角设置为 30 度，这大约对应于人类看起来自然的视野（与非常宽或非常窄的视野相比）。

之后，我们像为视频背景相机那样设置视口。此外，我们告诉视口删除其深度缓冲区，但保留颜色和模板缓冲区，使用`setClearFlags(false, true, false)`。我们这样做是为了确保我们的 3D 模型始终在持有视频纹理的四边形前面渲染，无论它们在实际对象空间中是位于四边形前面还是后面（请注意，我们所有的图形对象都引用在同一个世界坐标系中）。我们不清理颜色缓冲区，否则，先前渲染到颜色缓冲区的视频背景的颜色值将被删除，我们将只能看到这个视口（蓝色）的背景颜色。如果你现在运行你的应用程序，你应该能够看到你的视频背景前有一个行走的忍者，如下面这个相当酷的截图所示：

![使用场景图将 3D 模型叠加到相机视图中](img/8553_03_06.jpg)

# 改进叠加效果

在上一节中，你创建了一个透视相机，该相机以 30 度的垂直视场角渲染你的模型。然而，为了增加场景的真实感，实际上你希望尽可能匹配虚拟相机和物理相机的视场角。在像你的手机相机这样的通用成像系统中，这个视场角取决于相机传感器的尺寸和光学器件的焦距。焦距是衡量相机镜头将入射的平行光线弯曲到聚焦（在传感器平面上）的强度，基本上就是传感器平面与镜头的光学元件之间的距离。

视场（FOV）可以通过公式 *α = 2 arctan d/2f* 计算，其中 *d* 是相机传感器的（垂直、水平或对角线）范围，而 *2* 是焦距。听起来很简单，对吧？这里只有一个小挑战。你通常并不知道手机相机的（物理）传感器尺寸或焦距。前面公式的好处在于，你不需要知道传感器的物理范围或其焦距，但可以用任意坐标系（如像素）来计算。至于传感器尺寸，我们可以轻松使用相机的图像分辨率，这你在第二章《观察世界》中已经学会了如何查询。

最棘手的部分是估计你的相机焦距。有一些工具可以帮助你通过一组从已知物体拍摄的图片来完成这个任务；它们被称为相机重定工具（或几何相机校准工具）。我们将向你展示如何使用一个名为 GML C++相机校准工具箱的工具来实现这一点，你可以从[`graphics.cs.msu.ru/en/node/909`](http://graphics.cs.msu.ru/en/node/909)下载它。

安装工具后，在您的安卓手机上打开标准相机应用。在静态图像设置下选择与您在 JME 应用中使用的相机分辨率，例如，**640 x 480**，如下截图所示：

![改善叠加](img/8553_03_07.jpg)

打印出 GML 校准模式子目录中的`checkerboard_8x5_A4.pdf`文件，大小为 A4。用相机应用从不同的视角至少拍摄四张照片（6 到 8 张会更好）。尽量避免非常尖锐的角度，并尽量使棋盘格在图像中最大化。示例图像如下所示：

![改善叠加](img/8553_03_08.jpg)

完成后，将图像传输到计算机上的文件夹（例如，`AR4Android\calibration-images`）。之后，在计算机上启动 GML 相机校准应用并创建一个新项目。在**新建项目**对话框中输入黑白方格的正确数量（例如，`5`和`8`），如下截图所示：

![改善叠加](img/8553_03_12.jpg)

实际测量方格大小也至关重要，因为您的打印机可能会将 PDF 缩放到纸张大小。然后，点击**确定**，开始添加您刚才拍摄的照片（导航至**对象检测** | **添加图片**）。添加所有图片后，导航至**对象检测** | **检测所有**，然后是**校准** | **校准**。如果校准成功，您应该在结果标签中看到相机参数。我们主要对**焦距**部分感兴趣。虽然 x 轴和 y 轴有两个不同的焦距，但使用第一个即可。在三星 Galaxy SII 拍摄的样本图像案例中，得到的焦距为 522 像素。

然后，您可以将这个数字与您的垂直图像分辨率一起代入前面的公式，得到视角的垂直角度（以弧度为单位）。由于 JME 需要以度为单位的角度，您只需应用这个因子：*180/PI*进行转换。如果您也在使用三星 Galaxy SII，应该得到大约 50 度的垂直视角，这相当于 35 毫米胶片格式中的大约 28 毫米焦距（广角镜头）。如果您将这个值代入`mForegroundCamFOVY`变量并上传应用，行走忍者应该会显示得更小，如下所示。当然，您可以通过调整相机位置再次增加其大小。

请注意，您无法在 JME 中模拟物理相机的所有参数。例如，您不能轻松地将物理相机的主点与 JME 相机设置对齐。

### 注意

JME 也不支持直接的镜头畸变校正。您可以通过高级镜头校正技术来考虑这些影响，例如，这里介绍的技术：[`paulbourke.net/miscellaneous/lenscorrection/`](http://paulbourke.net/miscellaneous/lenscorrection/)。

![改善叠加效果](img/8553_03_13.jpg)

# 总结

在本章中，我们向您介绍了 3D 渲染的概念、3D 虚拟相机以及增强现实中的 3D 叠加观念。我们阐述了虚拟相机的定义及其特性，并描述了内在相机参数对于精确增强现实的重要性。您还有机会开发了您的第一个 3D 叠加，并对移动相机进行校准以提高逼真度。然而，当您移动手机时，视频背景会发生变化，而 3D 模型保持原位。在下一章中，我们将解决增强现实应用程序的一个基本组成部分：注册。
