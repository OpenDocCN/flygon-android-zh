- en: Chapter 3. Superimposing the World
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三章. 叠加现实世界
- en: 'Now that you have a view of the physical world on your screen, our next goal
    is to overlay digital 3D models on top of it. Overlay in 3D as used in Augmented
    Reality, is different from basic 2D overlays possible with Adobe Photoshop or
    similar drawing applications (in which we only adjust the position of two 2D layers).
    The notion of 3D overlay involves the management and rendering of content with
    six degrees of freedom (translation and rotation in three dimensions) as shown
    in the following figure:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经在屏幕上看到了物理世界的视图，我们下一个目标是在其上叠加数字3D模型。在增强现实中使用的3D叠加与使用Adobe Photoshop或类似绘图应用程序的基本2D叠加（我们仅调整两个2D图层的位置）不同。3D叠加的概念涉及具有六个自由度（在三维度上进行平移和旋转）的内容管理和渲染，如下图所示：
- en: '![Superimposing the World](img/8553_03_01.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![叠加现实世界](img/8553_03_01.jpg)'
- en: In this chapter, we will guide you through the different concepts and present
    you with the best way to superimpose real and virtual content. We will successively
    describe the concept of real and virtual cameras, how to perform superimposition
    with our scene graph engine, and create high quality superimposition. First, let's
    discuss the 3D world and the virtual camera.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将引导你了解不同的概念，并为你提供最佳的方式将真实和虚拟内容叠加。我们将依次介绍真实和虚拟相机的概念，如何使用我们的场景图引擎进行叠加，以及如何创建高质量的叠加。首先，让我们讨论3D世界和虚拟相机。
- en: The building blocks of 3D rendering
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3D渲染的构建块
- en: Representing and rendering virtual 3D content operates in the same way as when
    you click a picture with a digital camera in the physical world. If you take a
    picture of your friend or a landscape, you will first check your subject with
    the naked eye and after that will look at it through the viewfinder of the camera;
    only then will you take the picture. These three different steps are the same
    with virtual 3D content. You do not have a physical camera taking pictures, but
    you will use a **virtual camera** to render your scene. Your virtual camera can
    be seen as a digital representation of a real camera and can be configured in
    a similar way; you can position your camera, change its field of view, and so
    on. With virtual 3D content, you manipulate a digital representation of a geometrical
    3D scene, which we simply call your virtual 3D scene or virtual world.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 表示和渲染虚拟3D内容的方式与你在物理世界中用数码相机拍照的方式相同。如果你给朋友或风景拍照，你首先会用肉眼检查你的拍摄对象，然后通过相机的取景器观察，最后才会拍照。这三种不同的步骤与虚拟3D内容相同。你没有用物理相机拍照，而是使用**虚拟相机**来渲染场景。你的虚拟相机可以看作是真实相机的数字表示，并且可以以类似的方式进行配置；你可以定位相机，改变其视野等。对于虚拟3D内容，你操作的是几何3D场景的数字表示，我们简单地称之为你的虚拟3D场景或虚拟世界。
- en: 'The three basic steps for rendering a scene using 3D computer graphics are
    shown in the following figure and consist of:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 使用3D计算机图形渲染场景的三个基本步骤如下所示，包括：
- en: Configuring your virtual 3D scene (objects position and appearance)
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置你的虚拟3D场景（对象的位置和外观）
- en: Configuring your virtual camera
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置你的虚拟相机
- en: Rendering the 3D scene with the virtual camera
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用虚拟相机渲染3D场景
- en: '![The building blocks of 3D rendering](img/8553_03_02.jpg)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![3D渲染的构建块](img/8553_03_02.jpg)'
- en: As we do real-time rendering for AR, you will repeat these steps in a loop;
    objects or cameras can be moved at each time frame (typically at 20-30 FPS).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们进行增强现实（AR）的实时渲染，你将需要循环执行这些步骤；在每一帧（通常为20-30 FPS）都可以移动对象或相机。
- en: While positioning objects in a scene, or the camera in a scene, we need a way
    of representing the location (and also the orientation) of objects as functions
    of each other. To do so, we generally use some spatial representation of the scene
    based on geometric mathematical models. The most common approach is to use **Euclidian
    geometry** and **coordinate systems**. A coordinate system defines a method of
    referencing an object (or point) in a space using a numerical representation to
    define this position (**coordinates**). Everything in your scene can be defined
    in a coordinate system, and coordinate systems can be related to each other using
    **transformations**.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在场景中定位物体或相机时，我们需要一种表示物体位置（以及方向）相对于彼此的方法。为此，我们通常使用基于几何数学模型的场景空间表示。最常见的方法是使用**欧几里得几何**和**坐标系**。一个坐标系定义了一种引用空间中物体（或点）的方法，使用数值表示来定义这个位置（**坐标**）。你的场景中的所有内容都可以在坐标系中定义，而坐标系之间可以通过**变换**相互关联。
- en: 'The most common coordinate systems are shown in the following figure and are:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是最常见的坐标系：
- en: '**World Coordinate System**: It is the ground where you reference everything.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**世界坐标系**：这是你引用所有事物的地面。'
- en: '**Camera Coordinate System**: It is placed in the world coordinate system and
    used to render your scene seen from this specific viewpoint. It is sometimes also
    referenced as the Eye Coordinate System.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**相机坐标系**：它放置在世界坐标系中，用于从这个特定的视角渲染你的场景。有时也被称为视点坐标系。'
- en: '**Local Coordinate System(s)**: It is, for example, an object coordinate system,
    used to represent the 3D points of an object. Traditionally, you use the (geometric)
    center of your object to define your local coordinate system.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**局部坐标系**：例如，一个物体坐标系，用于表示一个物体的3D点。传统上，你可以使用物体的（几何）中心来定义你的局部坐标系。'
- en: '![The building blocks of 3D rendering](img/8553_03_03.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![3D渲染的构建块](img/8553_03_03.jpg)'
- en: Tip
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: 'There are two conventions for the orientation of the coordinate systems: left-handed
    and right-handed. In both the conventions, X goes on the right-hand side and Y
    goes upwards. Z goes towards you in the right-handed convention and away from
    you in the left-handed convention.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 坐标系的方向有左右手两种约定：在两种约定中，X轴都在右侧，Y轴向上。在右手坐标系中，Z轴指向你；而在左手坐标系中，Z轴远离你。
- en: Another common coordinate system, not illustrated here, is the image coordinate
    system. You are probably familiar with this one if you edit your pictures. It
    defines the position of each pixel of your image from a referenced origin (commonly
    the top-left corner or the bottom-left corner of an image). When you perform 3D
    graphics rendering, it's the same concept. Now we will focus on the virtual camera
    characteristics.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个常见的坐标系在这里没有说明，是图像坐标系。如果你编辑图片，你可能对这个很熟悉。它定义了从参考原点（通常是图像的左上角或左下角）开始的每个像素的位置。当你进行3D图形渲染时，概念是相同的。现在我们将关注虚拟相机的特性。
- en: Real camera and virtual camera
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实际相机与虚拟相机。
- en: 'A virtual camera for 3D graphics rendering is generally represented by two
    main sets of parameters: the **extrinsic** and **intrinsic** parameters. The extrinsic
    parameters define the location of the camera in the virtual world (the transformation
    from the world coordinate system to the camera coordinate system and vice versa).
    The intrinsic parameters define the projective properties of the camera, including
    its field of view (focal length), image center, and skew. Both the parameters
    can be represented with different data structures, with the most common being
    a matrix.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 用于3D图形渲染的虚拟相机通常由两组主要参数表示：**外参**和**内参**。外参定义了相机在虚拟世界中的位置（从世界坐标系到相机坐标系的变换以及反之）。内参定义了相机的投影属性，包括其视场（焦距）、图像中心和倾斜。这两种参数可以用不同的数据结构表示，最常见的是矩阵。
- en: 'If you develop a 3D mobile game, you are generally free to configure the cameras
    the way you want; you can put the camera above a 3D character running on a terrain
    (extrinsic) or set up a large field of view to have a large view of the character
    and the terrain (intrinsic). However, when you do Augmented Reality, the choice
    is constrained by the properties of the real camera in your mobile phone. In AR,
    we want properties of the virtual camera to match those of the real camera: the
    field of view and the camera position. This is an important element of AR, and
    we will explain how to realize it further in this chapter.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您开发的是一款3D移动游戏，通常可以自由配置摄像头；您可以将摄像头放置在在地形上奔跑的3D角色上方（外置）或设置一个大的视场角以获得角色和地形的大范围视图（内置）。然而，当您进行增强现实（AR）时，选择会受到手机中真实摄像头属性的制约。在AR中，我们希望虚拟摄像头的属性与真实摄像头相匹配：视场角和摄像头位置。这是AR的一个重要元素，我们将在本章中进一步解释如何实现它。
- en: Camera parameters (intrinsic orientation)
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摄像头参数（内在方向）
- en: The extrinsic parameters of the virtual camera will be explored in subsequent
    chapters; they are used for 3D registration in Augmented Reality. For our 3D overlay,
    we will now explore the intrinsic camera parameters.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在后续章节中探讨虚拟摄像头的 extrinsic 参数；它们用于增强现实中的3D注册。对于我们的3D叠加，我们现在将探讨摄像头的 intrinsic
    参数。
- en: 'There are different computational models for representing a virtual camera
    (and its parameters) and we will use the most popular one: the pinhole camera
    model. The pinhole camera model is a simplified model of a physical camera, where
    you consider that there is only a single point (pinhole) where light enters your
    camera image. With this assumption, computer vision researchers simplify the description
    of the intrinsic parameters as:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 有不同的计算模型可以表示虚拟摄像头（及其参数），我们将使用最流行的模型：针孔摄像头模型。针孔摄像头模型是对物理摄像头的简化模型，在这里您认为只有一个点（针孔）光线进入摄像头图像。有了这个假设，计算机视觉研究者简化了内在参数的描述如下：
- en: '**Focal length of your (physical or virtual) lens**: This together with the
    size of the camera center determines the **field of view** (**FOV**)—also called
    the angle of view—of your camera. The FOV is the extent of the object space your
    camera can see and is represented in radians (or degrees). It can be determined
    for the horizontal, vertical, and diagonal direction of your camera sensor.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**（物理或虚拟）镜头的焦距**：这和摄像头中心的尺寸一起决定了摄像头的**视场角**（**FOV**）——也称为视角。FOV是摄像头可以看到的对象空间的范围，用弧度（或度）表示。它可以确定摄像头传感器的水平、垂直和斜向的视角。'
- en: '**Image center (principal point)**: This accommodates any displacement of the
    sensor from the center position.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像中心（主点）**：这适用于传感器从中心位置的任何位移。'
- en: '**Skew factor**: This is used for non-square pixels.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**倾斜因子**：这用于非方形像素。'
- en: Note
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: On non-mobile cameras you should also consider the lens distortion, such as
    the radial and the tangential distortions. They can be modeled and corrected with
    advanced software algorithms. Lens distortions on mobile phone cameras are usually
    corrected in hardware.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在非移动摄像头中，您还应该考虑镜头畸变，比如径向畸变和切向畸变。它们可以通过先进的软件算法进行建模和校正。手机摄像头上的镜头畸变通常在硬件中进行校正。
- en: With all these concepts in mind, let's do a bit of practice now.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些概念，现在让我们进行一些实践操作。
- en: Using the scenegraph to overlay a 3D model onto the camera view
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用场景图将3D模型叠加到摄像头视图中
- en: In the previous chapter you learned how to set up a single viewport and camera
    to render the video background. While the virtual camera determines how your 3D
    graphics are projected on a 2D image plane, the viewport defines the mapping of
    this image plane to a part of the actual window in which your application runs
    (or the whole screen of the smartphone if the app runs in fullscreen mode). It
    determines the portion of the application window in which graphics are rendered.
    Multiple viewports can be stacked and can cover the same or different screen areas
    as shown in the following figure. For a basic AR application, you typically have
    two viewports. One is associated with the camera rendering the background video
    and one is used with a camera rendering the 3D objects. Typically, these viewports
    cover the whole screen.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，你学习了如何设置单个视口和相机来渲染视频背景。虚拟相机决定了你的3D图形如何投射到2D图像平面上，而视口定义了将此图像平面映射到应用程序实际运行窗口的一部分（或智能手机的全屏，如果应用以全屏模式运行）。它决定了应用程序窗口中渲染图形的部分。多个视口可以堆叠并覆盖相同的或不同的屏幕区域，如下所示。对于基本的AR应用，你通常有两个视口。一个与渲染背景视频的相机相关联，另一个与渲染3D对象的相机一起使用。通常，这些视口覆盖整个屏幕。
- en: '![Using the scenegraph to overlay a 3D model onto the camera view](img/8553_03_04.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![使用场景图将3D模型覆盖到相机视图上](img/8553_03_04.jpg)'
- en: The viewport size is not defined in pixels but is unitless and is defined from
    0 to 1 for the width and height to be able to easily adapt to changing window
    sizes. One camera is associated with one viewport at a time.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 视口大小不是以像素为单位定义的，而是无单位的，从0到1定义宽度和高度，以便能够轻松适应窗口大小的变化。一次只将一个相机关联到一个视口。
- en: 'Remember that for the video background we used an orthographic camera to avoid
    perspective foreshortening of the video image. However, this perspective is crucial
    for getting a proper visual impression of your 3D objects. Orthographic (parallel)
    projection (on the left-hand side of the following figure) and perspective projection
    (on the right-hand side of the following figure) determine how the 3D volume is
    projected on a 2D image plane as shown in the following figure:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，对于视频背景，我们使用了正交相机以避免视频图像的透视缩短。然而，这种透视对于正确视觉感受3D对象至关重要。正交（平行）投影（在以下图的左侧）和透视投影（在以下图的右侧）决定了如何将3D体积投射到2D图像平面上，如下所示：
- en: '![Using the scenegraph to overlay a 3D model onto the camera view](img/8553_03_05a_FINAL.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![使用场景图将3D模型覆盖到相机视图上](img/8553_03_05a_FINAL.jpg)'
- en: JME uses a right-handed coordinate system (OpenGL® convention, x on the right-hand
    side, y upwards, and z towards you). You certainly want 3D objects to appear bigger
    as the camera moves closer to them and smaller as it moves away. So how do we
    go along? Right, you just add a second camera—this time a perspective one—and
    an associated viewport that also covers the whole application window.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: JME使用右手坐标系（OpenGL®约定，x在右侧，y向上，z朝向你）。你当然希望随着相机靠近3D对象，它们看起来会更大，远离时则更小。那么我们该如何操作呢？没错，你只需添加第二个相机——这次是透视相机——以及一个关联的视口，这个视口也覆盖整个应用程序窗口。
- en: 'In the `SuperimposeJME` project associated with this chapter, we again have
    Android activity (`SuperimposeJMEActivity.java`) and a JME application class (`SuperimposeJME.java`).
    The application needs no major change from our previous project; you only have
    to extend the JME `SimpleApplication` class. In its `simpleInitApp()` startup
    method, we now explicitly differentiate between the initialization of the scene
    geometry (video background: `initVideoBackground()`; 3D foreground scene: `initForegroundScene()`)
    and the associated cameras and viewports:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章相关的`SuperimposeJME`项目中，我们同样拥有一个Android活动(`SuperimposeJMEActivity.java`)和一个JME应用程序类(`SuperimposeJME.java`)。应用程序无需对我们的上一个项目进行重大更改；你只需继承JME的`SimpleApplication`类即可。在其`simpleInitApp()`启动方法中，我们现在明确区分场景几何（视频背景：`initVideoBackground()`；3D前景场景：`initForegroundScene()`）及其相关相机和视口的初始化：
- en: '[PRE0]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note that the order in which the camera and viewports are initialized is important.
    Only when we first add the camera and viewport for the video background (`initBackgroundCamera()`)
    and later add the foreground camera and viewport (`initForegroundCamera()`), can
    we ensure that our 3D objects are rendered on top of the video background; otherwise,
    you would only see the video background.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，初始化摄像头和视口（viewport）的顺序很重要。只有当我们首先添加视频背景的摄像头和视口（`initBackgroundCamera()`），然后添加前景摄像头和视口（`initForegroundCamera()`），才能确保我们的3D对象渲染在视频背景之上；否则，你只能看到视频背景。
- en: We will now add your first 3D model into the scene using `initForegroundScene()`.
    A convenient feature of JME is that it supports the loading of external assets—for
    example, Wavefront files (`.obj`) or Ogre3D files (.`mesh.xml`/`.scene`)—including
    animations. We will load and animate a green ninja, a default asset that ships
    with JME.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们使用`initForegroundScene()`将你的第一个3D模型添加到场景中。JME的一个便捷特性是它支持加载外部资源——例如Wavefront文件（`.obj`）或Ogre3D文件（`.mesh.xml`/`.scene`）——包括动画。我们将加载并动画化一个绿色忍者，这是JME自带的一个默认资源。
- en: '[PRE1]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: So in this method you load a model relative to your project's `root`/`asset`
    folder. If you want to load other models, you also place them in this `asset`
    folder. You scale, translate, and orient it and then add it to the root scenegraph
    node. To make the model visible, you also add a directional light shining from
    the top front onto the model (you can try not adding the light and see the result).
    For the animation, access the "Walk" animation sequence stored in the model. In
    order to do this, your class needs to implement the `AnimEventListener` interface
    and you need to use an `AnimControl` instance to access that animation sequence
    in the model. Finally, you will assign the "Walk" sequence to an `AnimChannel`
    instance, tell it to loop the animation, and set the animation speed.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个方法中，你相对于项目的`root`/`asset`文件夹加载一个模型。如果你想加载其他模型，也请将它们放在这个`asset`文件夹中。你对模型进行缩放、平移和定位，然后将其添加到根场景图节点。为了使模型可见，你还需要添加一个从顶部前方照射到模型的方向光（你可以尝试不添加光看看结果）。对于动画，访问模型中存储的“Walk”动画序列。为此，你的类需要实现`AnimEventListener`接口，并使用`AnimControl`实例来访问该模型中的动画序列。最后，你将“Walk”序列分配给一个`AnimChannel`实例，告诉它循环动画，并设置动画速度。
- en: Great, you have now loaded your first 3D model, but you still need to display
    it on the screen.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 很好，现在你已经加载了你的第一个3D模型，但你仍然需要在屏幕上显示它。
- en: This is what you do next in `initForegroundCamera(fovY)`. It takes care of setting
    up the perspective camera and the associated viewport for your 3D model. As the
    perspective camera is characterized by the spatial extent of the object space
    it can see (the FOV), we pass the vertical angle of view stored in `mForegroundCamFOVY`
    to the method.It then attaches the root node of our scene containing the 3D model
    to the foreground viewport.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来在`initForegroundCamera(fovY)`中你会这样做。它负责为你的3D模型设置透视摄像头和相关视口。由于透视摄像头由其能看到的物体空间范围（即视场角FOV）来定义，我们将存储在`mForegroundCamFOVY`中的垂直视角传递给该方法。然后它将包含3D模型的场景根节点附着到前景视口。
- en: '[PRE2]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: While you could just copy some standard parameters from the default camera (similar
    to what we did with the video background camera), it is good to know which steps
    you actually have to do to initialize a new camera. After creating a perspective
    camera initialized with the window width and height, you set both the location
    (`setLocation()`) and the rotation (`setAxes()`) of the camera. JME uses a right-handed
    coordinate system, and our camera is configured to look along the negative z axis
    into the origin just as depicted in the previous figure. In addition, we set the
    vertical angle of the view passed to `setFrustumPerspective()` to 30 degrees,
    which corresponds approximately with a field of view that appears natural to a
    human (as opposed to a very wide or very narrow field of view).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管你可以直接复制一些默认摄像头的标准参数（类似于我们对视频背景摄像头所做的），但了解实际上需要执行哪些步骤来初始化新摄像头是很有好处的。在用窗口宽度和高度初始化透视摄像头后，你需要设置摄像头的位置（`setLocation()`）和旋转（`setAxes()`）。JME使用右手坐标系，我们的摄像头配置为沿着负z轴看向原点，正如前一个图所示。此外，我们将传递给`setFrustumPerspective()`的垂直视角设置为30度，这大约对应于人类看起来自然的视野（与非常宽或非常窄的视野相比）。
- en: 'Afterwards, we set up the viewport as we did for the video background camera.
    In addition, we tell the viewport to delete its depth buffer but retain the color
    and stencil buffers with `setClearFlags(false, true, false)`. We do this to ensure
    that our 3D models are always rendered in front of the quadrilateral holding the
    video texture, no matter if they are actually before or behind that quad in object
    space (beware that all our graphical objects are referenced in the same world
    coordinate system). We do not clear the color buffer as, otherwise, the color
    values of the video background, which are previously rendered into the color buffer
    will be deleted and we will only see the background color of this viewport (blue).
    If you run your application now, you should be able to see a walking ninja in
    front of your video background, as shown in the following pretty cool screenshot:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们像为视频背景相机那样设置视口。此外，我们告诉视口删除其深度缓冲区，但保留颜色和模板缓冲区，使用`setClearFlags(false, true,
    false)`。我们这样做是为了确保我们的3D模型始终在持有视频纹理的四边形前面渲染，无论它们在实际对象空间中是位于四边形前面还是后面（请注意，我们所有的图形对象都引用在同一个世界坐标系中）。我们不清理颜色缓冲区，否则，先前渲染到颜色缓冲区的视频背景的颜色值将被删除，我们将只能看到这个视口（蓝色）的背景颜色。如果你现在运行你的应用程序，你应该能够看到你的视频背景前有一个行走的忍者，如下面这个相当酷的截图所示：
- en: '![Using the scenegraph to overlay a 3D model onto the camera view](img/8553_03_06.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![使用场景图将3D模型叠加到相机视图中](img/8553_03_06.jpg)'
- en: Improving the overlay
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 改进叠加效果
- en: In the previous section you created a perspective camera, which renders your
    model with a vertical field of view of 30 degrees. However, to increase the realism
    of your scene, you actually want to match the field of view of your virtual and
    physical cameras as well as possible. This field of view in a general imaging
    system such as your phone's camera is dependent both on the size of the camera
    sensor and the focal length of the optics used. The focal length is a measure
    of how strongly the camera lens bends incoming parallel light rays until they
    come into focus (on the sensor plane), it is basically the distance between the
    sensor plane and the optical elements of your lens.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，你创建了一个透视相机，该相机以30度的垂直视场角渲染你的模型。然而，为了增加场景的真实感，实际上你希望尽可能匹配虚拟相机和物理相机的视场角。在像你的手机相机这样的通用成像系统中，这个视场角取决于相机传感器的尺寸和光学器件的焦距。焦距是衡量相机镜头将入射的平行光线弯曲到聚焦（在传感器平面上）的强度，基本上就是传感器平面与镜头的光学元件之间的距离。
- en: The FOV can be computed from the formula *α = 2 arctan d/2f*, where *d* is the
    (vertical, horizontal, or diagonal) extent of the camera sensor and *2* is the
    focal length. Sounds easy, right? There is only a small challenge. You most often
    do not know the (physical) sensor size or the focal length of the phone camera.
    The good thing about the preceding formula is that you do not need to know the
    physical extent of your sensor or its focal length but can calculate it in arbitrary
    coordinates such as pixels. And for the sensor size, we can easily use the resolution
    of the camera image, which you already learned to query in [Chapter 2](ch02.html
    "Chapter 2. Viewing the World"), *Viewing the World*.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 视场（FOV）可以通过公式 *α = 2 arctan d/2f* 计算，其中 *d* 是相机传感器的（垂直、水平或对角线）范围，而 *2* 是焦距。听起来很简单，对吧？这里只有一个小挑战。你通常并不知道手机相机的（物理）传感器尺寸或焦距。前面公式的好处在于，你不需要知道传感器的物理范围或其焦距，但可以用任意坐标系（如像素）来计算。至于传感器尺寸，我们可以轻松使用相机的图像分辨率，这你在[第2章](ch02.html
    "第2章. 观察世界")《观察世界》中已经学会了如何查询。
- en: The trickiest part is to estimate the focal length of your camera. There are
    some tools that help you to do just this using a set of pictures taken from a
    known object; they are called camera resectioning tools (or geometric camera calibration
    tools). We will show you how to achieve this with a tool called GML C++ Camera
    Calibration Toolbox, which you can download from [http://graphics.cs.msu.ru/en/node/909](http://graphics.cs.msu.ru/en/node/909).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 最棘手的部分是估计你的相机焦距。有一些工具可以帮助你通过一组从已知物体拍摄的图片来完成这个任务；它们被称为相机重定工具（或几何相机校准工具）。我们将向你展示如何使用一个名为GML
    C++相机校准工具箱的工具来实现这一点，你可以从[http://graphics.cs.msu.ru/en/node/909](http://graphics.cs.msu.ru/en/node/909)下载它。
- en: 'After installing the tool, open the standard camera app on your Android phone.
    Under the still image settings select the camera resolution that you also use
    in your JME application, for example, **640 x 480**, as shown in the following
    screenshot:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 安装工具后，在您的安卓手机上打开标准相机应用。在静态图像设置下选择与您在JME应用中使用的相机分辨率，例如，**640 x 480**，如下截图所示：
- en: '![Improving the overlay](img/8553_03_07.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![改善叠加](img/8553_03_07.jpg)'
- en: 'Take an A4 size printout of the `checkerboard_8x5_A4.pdf` file in the GML Calibration
    pattern subdirectory. Take at least four pictures with your camera app from different
    viewpoints (6 to 8 pictures will be better). Try to avoid very acute angles and
    try to maximize the checkerboards in the image. Example images are depicted in
    the following figure:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 打印出GML校准模式子目录中的`checkerboard_8x5_A4.pdf`文件，大小为A4。用相机应用从不同的视角至少拍摄四张照片（6到8张会更好）。尽量避免非常尖锐的角度，并尽量使棋盘格在图像中最大化。示例图像如下所示：
- en: '![Improving the overlay](img/8553_03_08.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![改善叠加](img/8553_03_08.jpg)'
- en: 'When you are done, transfer the images to a folder on your computer (for example,
    `AR4Android\calibration-images`). Afterwards, start the GML Camera Calibration
    app on your computer and create a new project. Type into the **New project** dialog
    box the correct number of black and white squares (for example, `5` and `8`),
    as shown in the following screenshot:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，将图像传输到计算机上的文件夹（例如，`AR4Android\calibration-images`）。之后，在计算机上启动GML相机校准应用并创建一个新项目。在**新建项目**对话框中输入黑白方格的正确数量（例如，`5`和`8`），如下截图所示：
- en: '![Improving the overlay](img/8553_03_12.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![改善叠加](img/8553_03_12.jpg)'
- en: It is also crucial to actually measure the square size as your printer might
    scale the PDF to its paper size. Then, click on **OK** and start adding the pictures
    you have just taken (navigate to **Object detection** | **Add image**). When you
    have added all the images, navigate to **Object detection** | **Detect All** and
    then **Calibration** | **Calibrate**. If the calibration was successful, you should
    see camera parameters in the result tab. We are mostly interested in the **Focal
    length** section. While there are two different focal lengths for the x and y
    axes, it is fine to just use the first one. In the sample case of the images,
    which were taken with a Samsung Galaxy SII, the resulting focal length is 522
    pixels.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 实际测量方格大小也至关重要，因为您的打印机可能会将PDF缩放到纸张大小。然后，点击**确定**，开始添加您刚才拍摄的照片（导航至**对象检测** | **添加图片**）。添加所有图片后，导航至**对象检测**
    | **检测所有**，然后是**校准** | **校准**。如果校准成功，您应该在结果标签中看到相机参数。我们主要对**焦距**部分感兴趣。虽然x轴和y轴有两个不同的焦距，但使用第一个即可。在三星Galaxy
    SII拍摄的样本图像案例中，得到的焦距为522像素。
- en: 'You can then plug this number together with your vertical image resolution
    into the preceding formula and retrieve the vertical angle of the view in radians.
    As JME needs the angle in degrees, you simply convert it by applying this factor:
    *180/PI*. If you are also using a Samsung Galaxy SII, a vertical angle of view
    of approximately 50 degrees should result, which equals a focal length of approximately
    28 mm in 35 mm film format (wide angle lens). If you plug this into the `mForegroundCamFOVY`
    variable and upload the application, the walking ninja should appear smaller as
    shown in the following figure. Of course, you can increase its size again by adjusting
    the camera position.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您可以将这个数字与您的垂直图像分辨率一起代入前面的公式，得到视角的垂直角度（以弧度为单位）。由于JME需要以度为单位的角度，您只需应用这个因子：*180/PI*进行转换。如果您也在使用三星Galaxy
    SII，应该得到大约50度的垂直视角，这相当于35毫米胶片格式中的大约28毫米焦距（广角镜头）。如果您将这个值代入`mForegroundCamFOVY`变量并上传应用，行走忍者应该会显示得更小，如下所示。当然，您可以通过调整相机位置再次增加其大小。
- en: Note that you cannot model all parameters of the physical camera in JME. For
    example, you cannot easily set the principal point of your physical camera with
    your JME camera.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，您无法在JME中模拟物理相机的所有参数。例如，您不能轻松地将物理相机的主点与JME相机设置对齐。
- en: Note
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'JME also doesn''t support direct lens distortion correction. You can account
    for these artifacts via advanced lens correction techniques covered, for example,
    here: [http://paulbourke.net/miscellaneous/lenscorrection/](http://paulbourke.net/miscellaneous/lenscorrection/).'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: JME也不支持直接的镜头畸变校正。您可以通过高级镜头校正技术来考虑这些影响，例如，这里介绍的技术：[http://paulbourke.net/miscellaneous/lenscorrection/](http://paulbourke.net/miscellaneous/lenscorrection/)。
- en: '![Improving the overlay](img/8553_03_13.jpg)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![改善叠加效果](img/8553_03_13.jpg)'
- en: Summary
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this chapter, we introduced you to the concept of 3D rendering, the 3D virtual
    camera, and the notion of 3D overlay for Augmented Reality. We presented what
    a virtual camera is and its characteristics and described the importance of intrinsic
    camera parameters for accurate Augmented Reality. You also got a chance to develop
    your first 3D overlay and calibrate your mobile camera for improved realism. However,
    as you move your phone along, the video background changes, while the 3D models
    stay in place. In the next chapter, we will tackle one of the fundamental bricks
    of an Augmented Reality application: the registration.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们向您介绍了3D渲染的概念、3D虚拟相机以及增强现实中的3D叠加观念。我们阐述了虚拟相机的定义及其特性，并描述了内在相机参数对于精确增强现实的重要性。您还有机会开发了您的第一个3D叠加，并对移动相机进行校准以提高逼真度。然而，当您移动手机时，视频背景会发生变化，而3D模型保持原位。在下一章中，我们将解决增强现实应用程序的一个基本组成部分：注册。
