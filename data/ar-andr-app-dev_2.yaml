- en: Chapter 2. Viewing the World
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2章. 观察世界
- en: 'In this chapter, we will learn how to develop the first element of any mobile
    AR application: *the view of the real world*. To understand the concept of the
    view of the real world, we will take a look at the camera application you have
    installed on your mobile. Open any photo capture application (camera app) you
    have preinstalled on your android device, or you may have downloaded from the
    Google Play store (such as Camera Zoom FX, Vignette, and so on). What you can
    see on the viewfinder of the application is a real-time video stream captured
    by the camera and displayed on your screen.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习如何开发任何移动AR应用程序的第一个元素：*真实世界的视图*。为了理解真实世界视图的概念，我们将看看你安装在手机上的摄像头应用程序。打开你预装在安卓设备上的任何照片拍摄应用程序（摄像头应用），或者你可能从谷歌应用商店下载的应用（如Camera
    Zoom FX、Vignette等）。你在应用程序取景器上看到的是摄像头捕获的实时视频流，并显示在你的屏幕上。
- en: If you move the device around while running the application, it seems like you
    were seeing the real world "through" the device. Actually, the camera seems to
    act like the eye of the device, perceiving the environment around you. This process
    is also used for mobile AR development to create a view of the real world. It's
    the concept of see-through video that we introduced in the previous chapter.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行应用程序时移动设备，仿佛你通过设备看到了真实世界。实际上，摄像头就像是设备的眼睛，感知你周围的环境。这个过程也用于移动AR开发，以创建真实世界的视图。这是我们在前一章中介绍的透视视频的概念。
- en: 'The display of the real world requires two main steps:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 显示真实世界需要两个主要步骤：
- en: Capturing an image from the camera (camera access)
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从摄像头捕获图像（摄像头访问）
- en: Displaying this image on the screen using a graphics library (camera display
    in JME)
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用图形库在屏幕上显示这个图像（在JME中显示摄像头）
- en: 'This process is generally repeated in an infinite loop, creating the *real-time*
    aspect of the view of the physical world. In this chapter, we will discuss how
    to implement both of these techniques using two different graphics libraries:
    a low-level one (Android library) and a high-end one (JME 3D scene graph library).
    While the Android library allows you to quickly display the camera image, it is
    not designed to be combined with 3D graphics, which you want to augment on the
    video stream. Therefore, you will implement the camera display also using the
    JME library. We will also introduce challenges and hints for handling a variety
    of Android smartphones and their inbuilt cameras.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程通常在一个无限循环中重复，创建了物理世界视图的*实时*特性。在本章中，我们将讨论如何使用两个不同的图形库实现这两种技术：一个低级别的（Android库）和一个高级的（JME
    3D场景图库）。虽然Android库能让你快速显示摄像头图像，但它并非设计为与你想在视频流上增强的3D图形结合使用。因此，你也将使用JME库实现摄像头显示。我们还将介绍处理各种Android智能手机及其内置摄像头的挑战和提示。
- en: Understanding the camera
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解摄像头
- en: 'Phone manufacturers are always competing to equip your smartphone with the
    most advanced camera sensor, packing it with more features, such as higher resolution,
    better contrast, faster video capture, new autofocus mode, and so on. The consequence
    is that the capabilities (features) of the mobile phone cameras can differ significantly
    between smartphone models or brands. Thankfully, the Google Android API provides
    a generic wrapper for the underlying camera hardware unifying the access for the
    developer: the Android camera API. For your development, an efficient access to
    the camera needs a clear understanding of the camera capabilities (parameters
    and functions) available through the API. Underestimating this aspect will result
    in slow-running applications or pixelated images, affecting the user experience
    of your application.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 手机制造商总是在竞相为你的智能手机配备最先进的摄像头传感器，加入更多功能，如更高的分辨率、更好的对比度、更快的视频捕捉、新的自动对焦模式等等。结果是，不同智能手机型号或品牌之间的手机摄像头功能（特性）可能存在显著差异。幸运的是，谷歌Android
    API为底层摄像头硬件提供了一个通用封装，统一了开发者的访问方式：即Android摄像头API。在开发过程中，高效地访问摄像头需要对API提供的摄像头功能（参数和函数）有清晰的理解。忽视这一点会导致应用程序运行缓慢或图像像素化，影响你的应用程序用户体验。
- en: Camera characteristics
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摄像头特性
- en: 'Cameras on smartphones nowadays share many characteristics with digital point-and-shoot
    cameras. They generally support two operative modes: the still image mode (which
    is an instantaneous, singular capture of an image), or the video mode (which is
    a continuous, real-time capture of images).'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 现今智能手机上的相机与数码傻瓜相机有许多共同特性。它们通常支持两种操作模式：静态图像模式（即瞬间捕捉的单个图像），或者视频模式（即连续实时捕捉图像）。
- en: 'Video and image modes differ in terms of capabilities: an image capture always
    has, for example, a higher resolution (more pixels) than video. While modern smartphones
    can easily achieve 8 megapixel in the still image mode, the video mode is restricted
    to 1080p (about 2 megapixels). In AR, we use the video mode in typically lower
    resolutions such as VGA (640 x 480) for efficiency reasons. Unlike a standard
    digital camera, we don''t store any content on an external memory card; we just
    display the image on the screen. This mode has a special name in the Android API:
    the preview mode.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 视频和图像模式在功能上有所不同：例如，图像捕捉总是具有比视频更高的分辨率（更多像素）。虽然现代智能手机在静态图像模式下轻松实现800万像素，但视频模式限制在1080p（约200万像素）左右。在增强现实（AR）中，我们通常使用较低分辨率如VGA（640
    x 480）的视频模式以提高效率。与标准数码相机不同，我们不将任何内容存储在外部存储卡上；我们只是在屏幕上显示图像。这个模式在Android API中有一个特殊的名字：预览模式。
- en: 'Some of the common settings (parameters) of the preview mode are:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 预览模式的一些常见设置（参数）包括：
- en: '**Resolution**: It is the size of the captured image, which can be displayed
    on your screen. This is also called the size in the Android camera API. Resolution
    is defined in pixels in terms of width (x) and height (y) of the image. The ratio
    between them is called the **aspect ratio**, which gives a sense of how square
    an image is similar to TV resolution (such as 1:1, 4:3, or 16:9).'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分辨率**：这是捕捉到的图像的大小，可以在你的屏幕上显示。在Android相机API中也被称为尺寸。分辨率以像素为单位定义图像的宽（x）和高（y）。它们之间的比率称为**宽高比**，这给出了图像与电视分辨率（如1:1、4:3或16:9）相似程度的感知。'
- en: '**Frame rate**: It defines how fast an image can be captured. This is also
    called **Frames Per Second** (**FPS**).'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**帧率**：它定义了图像可以捕捉的速度。这也被称为**每秒帧数**（**FPS**）。'
- en: '**White balance**: It determines what will be the white color on your image,
    mainly dependent on your environment light (for example, daylight for outdoor
    situation, incandescent at your home, fluorescent at your work, and so on).'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**白平衡**：它决定了图像上的白色会是什么样子，主要取决于你的环境光线（例如，户外情况下是日光，家里是白炽灯，工作场所是荧光灯等）。'
- en: '**Focus**: It defines which part of the image will appear sharp and which part
    will not be easily discernible (out of focus). Like any other camera, smartphone
    cameras also support autofocus mode.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**焦点**：它定义了图像中哪部分会显得清晰，哪部分不容易被辨识（失焦）。与其他相机一样，智能手机相机也支持自动对焦模式。'
- en: '**Pixel format**: The captured image is converted to a specific image format,
    where the color (and luminance) of each pixel is stored under a specific format.
    The pixel format not only defines the type of color channels (such as RGB versus
    YCbCr), but also the storage size of each component (for example, 5, 8, or 16
    bits). Some popular pixel formats are RGB888, RGB565, or YCbCr422\. In the following
    figure, you can see common camera parameters, moving from the left to right: image
    resolution, frame rate for capturing image streams, focus of the camera, the pixel
    format for storing the images and the white balance:![Camera characteristics](img/8553OS_02_01.jpg)'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**像素格式**：捕捉到的图像被转换成特定的图像格式，每个像素的颜色（和亮度）以特定格式存储。像素格式不仅定义了颜色通道的类型（如RGB与YCbCr），还定义了每个分量的存储大小（例如5位、8位或16位）。一些流行的像素格式包括RGB888、RGB565或YCbCr422。在下面的图中，你可以看到从左到右常见的相机参数：图像分辨率、捕捉图像流的帧率、相机焦点、存储图像的像素格式以及白平衡：![相机特性](img/8553OS_02_01.jpg)'
- en: 'Other important settings related to the camera workflow are:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 与相机工作流程相关的重要设置还有：
- en: '**Playback control**: Defines when you can start, pause, stop, or get the image
    content of your camera.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**播放控制**：定义了你可以开始、暂停、停止或获取相机图像内容的时间。'
- en: '**Buffer control**: A captured image is copied into the memory to be accessible
    to your application. There are different ways to store this image, for example,
    using a buffering system.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缓冲控制**：捕捉到的图像被复制到内存中，以便你的应用程序可以访问。存储这个图像有不同的方法，例如，使用缓冲系统。'
- en: 'Configuring these settings correctly is the basic requirement for an AR application.
    While popular camera apps use only the preview mode for capturing a video or an
    image, the preview mode is the basis for the view of the real world in AR. Some
    of the things you need to remember for configuring these camera parameters are:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 正确配置这些设置是AR应用的基本要求。尽管流行的相机应用仅使用预览模式来捕捉视频或图像，但预览模式是AR中现实世界视图的基础。你需要记住的一些关于配置这些相机参数的事情包括：
- en: The higher the resolution, the lower will be your frame rate, which means your
    application might look prettier if things do not move fast in the image, but will
    run more slowly. In contrast, you can have an application running fast but your
    image will look "blocky" (pixelated effect).
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分辨率越高，帧率越低，这意味着如果你的应用中图像内容移动不快，它看起来可能会更美观，但运行会更缓慢。相比之下，你可以让应用运行得更快，但图像看起来会变得“块状”（像素化效果）。
- en: If the white balance is not set properly, the appearance of digital models overlaid
    on the video image will not match and the AR experience will be diminished.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果白平衡设置不当，叠加在视频图像上的数字模型的外观将不匹配，AR体验将大打折扣。
- en: If the focus changes all the time (autofocus), you may not be able to analyze
    the content of the image and the other components of your application (such as
    tracking) may not work correctly.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果焦点不断变化（自动对焦），你可能无法分析图像的内容，应用的其他部分（如追踪）可能无法正确工作。
- en: Cameras on mobile devices use compressed image formats and typically do not
    offer the same performance as high-end desktop webcams. When you combine your
    video image (often in RGB565 with 3D rendered content using RGB8888), you might
    notice the color differences between them.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移动设备上的相机使用压缩图像格式，并且通常不具备高端桌面网络摄像头相同的性能。当你将视频图像（通常是RGB565格式与使用RGB8888格式的3D渲染内容结合）结合在一起时，你可能会注意到它们之间的颜色差异。
- en: If you are doing heavy processing on your image, that can create a delay in
    your application. Additionally, if your application runs multiple processes concurrently,
    synchronizing your image capture process with the other processes is rather important.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你在图像上进行大量处理，那可能会造成应用延迟。此外，如果你的应用同时运行多个进程，将图像捕获过程与其他进程同步是非常重要的。
- en: 'We advise you to:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建议你：
- en: Acquire and test a variety of Android devices and their cameras to get a sense
    of the camera capabilities and performances.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取并测试各种Android设备和它们的相机，以了解相机的功能和性能。
- en: Find a compromise between the resolution and frame rate. Standard resolution/frame
    rate combination used on desktop AR is 640 x 480 at 30 fps. Use it as a baseline
    for your mobile AR application and optimize from there to get a higher quality
    AR application for newer devices.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在分辨率和帧率之间找到平衡点。桌面AR上使用的标准分辨率/帧率组合是640 x 480，30 fps。将此作为你移动AR应用的基础，并在此基础上优化，以获得适用于新型设备的更高质量的AR应用。
- en: Optimize the white balance if your AR application is only supposed to be run
    in a specific environment such as in daylight for an outdoor application.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你的AR应用仅计划在特定环境中运行，例如白天户外应用，请优化白平衡。
- en: Controlling the focus has been one of the limiting aspects of Android smartphones
    (always on autofocus or configuration not available). Privilege a fixed focus
    over an autofocus, and optimize the focus range if you are developing a tabletop
    or room AR application (near focus) versus an outdoor AR application (far focus).
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 控制焦点一直是Android智能手机的限制因素之一（始终开启自动对焦或无法配置）。如果开发的是桌面或室内AR应用（近焦）相对于户外AR应用（远焦），请优先选择固定焦点，并优化焦点范围。
- en: Experiment with pixel formats, to get the best match with your rendered content.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实验不同的像素格式，以与你的渲染内容达到最佳匹配。
- en: Try to use an advanced buffering system, if available, on your target device.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果目标设备支持，尝试使用先进的缓冲系统。
- en: There are other major characteristics of the camera that are not available through
    the API (or only on some handheld devices), but are important to be considered
    during the development of your AR application. They are field of view, exposure
    time, and aperture.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一些通过API无法获取的（或在部分手持设备上才能获取的）相机主要特性，在开发AR应用时也应当考虑。这些特性包括视场、曝光时间和光圈。
- en: 'We will only discuss one of them here: the field of view. The field of view
    corresponds to how much the camera sees from the real world, such as how much
    your eyes can see from left to right and top to bottom (human vision is around
    120 degrees with a binocular vision). The field of view is measured in degrees,
    and varies largely between cameras (15 degrees to 60 degrees without distortion).'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我们只讨论其中之一：视野。视野对应于相机从现实世界中看到的内容，比如你的眼睛可以从左到右、从上到下看到多少（人类的双眼视觉大约是120度）。视野以度数测量，不同相机之间差异很大（15度至60度，无变形）。
- en: The larger your field of view is, the more you will capture the view of the
    real world and the better will be the experience. The field of view is dependent
    on the hardware characteristics of your camera (the sensor size and the focal
    length of the length). Estimating this field of view can be done with additional
    tools; we will explore this later on.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 你的视野越大，捕获的现实世界视野就越广，体验也越好。视野取决于相机的硬件特性（传感器尺寸和焦距）。可以使用额外的工具来估算这个视野；我们稍后会进行探讨。
- en: Camera versus screen characteristics
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相机与屏幕特性对比
- en: 'The camera and screen characteristics are generally not exactly the same on
    your mobile platform. The camera image can be, for example, larger than the screen
    resolution. The aspect ratio of the screen can also differ for one of the cameras.
    This is a technical challenge in AR as you want to find the best method to fit
    your camera image on the screen, to create a sense of AR display. You want to
    maximize the amount of information by putting as much of the camera image on your
    screen as possible. In the movie industry, they have a similar problem as the
    recorded format may differ from the playing media (for example, the cinemascope
    film on your 4:3 mobile device, the 4K movie resolution on your 1080p TV screen,
    and so on). To address this problem, you can use two fullscreen methods known
    as stretching and cropping, as shown in the following figure:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的移动平台上，相机和屏幕特性通常不完全相同。例如，相机图像可能比屏幕分辨率大。屏幕的宽高比也可能与其中一个相机不同。在增强现实（AR）中，这是一个技术挑战，因为你想找到最好的方法将相机图像适配到屏幕上，以创建AR显示的感觉。你希望尽可能多地将在相机图像上的信息显示在屏幕上。在电影行业，他们有类似的问题，因为记录的格式可能与播放媒体不同（例如，在4:3的移动设备上播放宽银幕电影，在1080p的电视屏幕上播放4K电影分辨率等）。为了解决这个问题，你可以使用两种全屏方法：拉伸和裁剪，如下图所示：
- en: '![Camera versus screen characteristics](img/8553OS_02_02.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![相机与屏幕特性对比](img/8553OS_02_02.jpg)'
- en: Stretching will adapt the camera image to the screen characteristics, at the
    risk of deforming the original format of the image (mainly its aspect ratio).
    Cropping will select a subarea of the image to be displayed and you will lose
    information (it basically zooms into the image until the whole screen is filled).
    Another approach will be to change the scale of your image, so that one dimension
    (width or height) of the screen and the image are the same. Here, the disadvantage
    is that you will lose the fullscreen display of your camera image (a black border
    will appear on the side of your image). None of the techniques are optimal, so
    you need to experiment what is more convenient for your application and your target
    devices.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 拉伸会根据屏幕特性调整相机图像，这可能会导致图像原始格式（主要是宽高比）的变形。裁剪会选择图像的一个子区域进行显示，你会丢失一些信息（基本上是将图像放大，直到整个屏幕被填满）。另一种方法是改变图像的缩放比例，使得屏幕和图像的一个尺寸（宽度或高度）相同。这里的缺点是，你将无法全屏显示相机图像（图像边缘将出现黑边）。这些技术都不完美，因此你需要实验哪种方法对你的应用和目标设备更方便。
- en: Accessing the camera in Android
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Android中访问相机
- en: To start with, we will create a simple camera activity to get to know the principles
    of camera access in Android. While there are convenient Android applications that
    provide quick means for snapping a picture or recording a video through Android
    intents, we will get our hands dirty and use the Android camera API to get a customized
    camera access for our first application.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将创建一个简单的相机活动，以了解在Android中访问相机的原理。尽管有方便的Android应用程序可以通过Android意图快速抓拍照片或录制视频，但我们将会亲自动手，使用Android相机API为我们的第一个应用程序获得定制化的相机访问。
- en: 'We will guide you, step-by-step, in creating your first app showing a live
    camera preview. This will include:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将一步一步指导你创建你的第一个显示实时相机预览的应用程序。这将包括：
- en: Creating an Eclipse project
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个Eclipse项目
- en: Requesting relevant permissions in the Android Manifest file
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Android Manifest 文件中请求相关权限
- en: Creating SurfaceView to be able to capture the preview frames of the camera
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建 SurfaceView 以捕获相机的预览帧
- en: Creating an activity that displays the camera preview frames
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个显示相机预览帧的活动
- en: Setting camera parameters
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置相机参数
- en: Tip
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: '**Downloading the example code**'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**下载示例代码**'
- en: You can download the example code files for all Packt books you have purchased
    from your account at [http://www.packtpub.com](http://www.packtpub.com). If you
    purchased this book elsewhere, you can visit [http://www.packtpub.com/support](http://www.packtpub.com/support)
    and register to have the files e-mailed directly to you. You can also find the
    code files at [https://github.com/arandroidbook/ar4android](https://github.com/arandroidbook/ar4android).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从你在 [http://www.packtpub.com](http://www.packtpub.com) 的账户下载你所购买的 Packt 书籍的示例代码文件。如果你在别处购买了这本书，可以访问
    [http://www.packtpub.com/support](http://www.packtpub.com/support) 注册，直接通过电子邮件发送文件给你。你还可以在
    [https://github.com/arandroidbook/ar4android](https://github.com/arandroidbook/ar4android)
    找到代码文件。
- en: Creating an Eclipse project
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建一个 Eclipse 项目
- en: Our first step is the setup process for creating an Android project in Eclipse.
    We will call our first project `CameraAccessAndroid`. Please note that the description
    of this subsection will be similar for all other examples that we will present
    in this book.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一步是在 Eclipse 中创建 Android 项目的设置过程。我们将第一个项目命名为 `CameraAccessAndroid`。请注意，本小节的描述将与其他将在本书中展示的示例类似。
- en: 'Start your Eclipse project and go to **File** | **New** | **Android Application
    Project**. In the following configuration dialog box, please fill in the appropriate
    fields as shown in the following screenshot:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 启动你的 Eclipse 项目并转到 **文件** | **新建** | **Android 应用程序项目**。在接下来的配置对话框中，请按照以下截图填写适当的字段：
- en: '![Creating an Eclipse project](img/8553_02_03_FINAL.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![创建一个 Eclipse 项目](img/8553_02_03_FINAL.jpg)'
- en: Then, click on two more dialog boxes (**Configure Project** for selecting the
    file path to your project, **Launcher Icon**) by accepting the default values.
    Then, in the **Create Activity** dialog box, select the **Create Activity** checkbox
    and the **BlankActivity** option. In the following **New Blank Activity** dialog,
    fill into the **Activity Name** textbox, for example, with `CameraAccessAndroidActivity`
    and leave the **Layout Name** textbox to its default value. Finally, click on
    the **Finish** button and your project should be created and be visible in the
    project explorer.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，点击另外两个对话框（**配置项目** 选择到你的项目文件路径，**启动器图标**），接受默认值。接着，在 **创建活动** 对话框中，选中 **创建活动**
    复选框和 **空白活动** 选项。在接下来的 **新建空白活动** 对话框中，在 **活动名称** 文本框中填写，例如 `CameraAccessAndroidActivity`
    并将 **布局名称** 文本框保留为默认值。最后，点击 **完成** 按钮，你的项目应该会被创建并在项目浏览器中可见。
- en: Permissions in the Android manifest
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Android Manifest 中的权限
- en: 'For every AR application we will create, we will use the camera. With the Android
    API, you explicitly need to allow camera access in the Android manifest declaration
    of your application. In the top-level folder of your `CameraAccessAndroid` project,
    open the `AndroidManifest.xml` file in the text view. Then add the following permission:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们将要创建的每个 AR 应用程序，我们将使用相机。使用 Android API，你需要在应用程序的 Android Manifest 声明中明确允许相机访问。在你的
    `CameraAccessAndroid` 项目的顶级文件夹中，以文本视图打开 `AndroidManifest.xml` 文件。然后添加以下权限：
- en: '[PRE0]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Besides this permission, the application also needs to at least declare the
    use of camera features:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 除了此权限，应用程序还需要至少声明使用相机功能：
- en: '[PRE1]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Since we want to run the AR application in fullscreen mode (for better immersion),
    add the following option into the activity tag:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们希望以全屏模式运行 AR 应用程序（以获得更好的沉浸感），请在活动标签中添加以下选项：
- en: '[PRE2]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Creating an activity that displays the camera
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建一个显示相机的活动
- en: 'In its most basic form, our `Activity` class takes care of setting up the `Camera`
    instance. As a class member, you need to declare an instance of a `Camera` class:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在最基本的形式中，我们的 `Activity` 类负责设置 `Camera` 实例。作为一个类成员，你需要声明一个 `Camera` 类的实例：
- en: '[PRE3]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The next step is to open the camera. To do that, we define a `getCameraInstance()`
    method:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是打开相机。为此，我们定义一个 `getCameraInstance()` 方法：
- en: '[PRE4]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'It is important that the `open()` call is surrounded by `try{}catch{}` blocks
    as the camera might currently be used by other processes and be unavailable. This
    method is called in the `onResume()` method of your `Activity` class:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '`open()` 调用被 `try{}catch{}` 块包围非常重要，因为相机可能当前正被其他进程使用而不可用。此方法在 `Activity` 类的
    `onResume()` 方法中调用：'
- en: '[PRE5]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'It is also crucial to properly release the camera when you pause or exit your
    program. Otherwise it will be blocked if you open another (or the same) program.
    We define a `releaseCamera()` method for this:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 当你暂停或退出程序时，正确释放摄像头同样重要。否则，如果你打开另一个（或相同的）程序，摄像头将被占用。我们为此定义了一个`releaseCamera()`方法：
- en: '[PRE6]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: You then call this method in the `onPause()` method of your `Activity` class.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你可以在`Activity`类的`onPause()`方法中调用这个方法。
- en: Note
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: On some devices, it can be slow to open the camera. In this case, you can use
    an `AsyncTask` class to mitigate the problem.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些设备上，打开摄像头可能会很慢。在这种情况下，你可以使用`AsyncTask`类来缓解这个问题。
- en: Setting camera parameters
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置摄像头参数
- en: You now have a basic workflow to start and stop your camera. The Android camera
    API also allows you to query and set various camera parameters that were discussed
    at the beginning of this chapter. Specifically, you should be careful not to use
    very high resolution images as they take a lot of processing power. For a typical
    mobile AR application, you do not want to have a higher video resolution of 640
    x 480 (VGA).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你已经有了启动和停止摄像头的的基本工作流程。Android摄像头API还允许你查询和设置本章开始时讨论的各种摄像头参数。特别是，你应该注意不要使用分辨率非常高的图像，因为它们会消耗大量处理能力。对于典型的移动AR应用，你不需要高于640
    x 480（VGA）的视频分辨率。
- en: As camera modules can be quite different, it is not advisable to hardcode the
    video resolution. Instead, it is a good practice to query the available resolutions
    of your camera sensor and only use the most optimal resolution for your application,
    if it is supported.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 由于摄像头模块可能存在很大差异，不建议硬编码视频分辨率。相反，查询摄像头传感器可用的分辨率，并根据你的应用程序只使用最合适的分辨率，这是一个好的做法（如果支持的话）。
- en: 'Let''s say, you have predefined the video width you want in the `mDesiredCameraPreviewWidth`
    variable. You can then check if the value of the width resolution (and an associated
    video height) is supported by the camera using the following method:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你已经在变量`mDesiredCameraPreviewWidth`中预定义了想要的视频宽度。你可以通过以下方法检查该宽度分辨率（以及相关的视频高度）是否被摄像头支持：
- en: '[PRE7]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The `mCamera.getParameters()` method is used to query the current camera parameters.
    The `mCamera.getParameters()` and `getSupportedPreviewSizes()` methods return
    the subset of available preview sizes and the `parameters.setPreviewSize` method
    is setting the new preview size. Finally, you have to call the `mCamera.setParameters(parameters)`
    method so that the requested changes are implemented. This `initializeCameraParameters()`
    method can then also be called in the `onResume()` method of your `Activity` class.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '`mCamera.getParameters()`方法用于查询当前的摄像头参数。`mCamera.getParameters()`和`getSupportedPreviewSizes()`方法返回可用的预览尺寸的子集，而`parameters.setPreviewSize`方法用于设置新的预览尺寸。最后，你需要调用`mCamera.setParameters(parameters)`方法，以便实施请求的更改。这个`initializeCameraParameters()`方法也可以在`Activity`类的`onResume()`方法中调用。'
- en: Creating SurfaceView
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建SurfaceView
- en: For your Augmented Reality application, you want to display a stream of live
    images from your back-facing camera on the screen. In a standard application,
    acquiring the video and displaying the video are two independent procedures. With
    the Android API, you explicitly need to have a separate SurfaceView to display
    the camera stream as well. The `SurfaceView` class is a dedicated drawing area
    that you can embed into your application.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 对于你的增强现实应用，你希望将后置摄像头的实时图像流显示在屏幕上。在标准应用中，获取视频和显示视频是两个独立的程序。使用Android API，你还需要一个单独的SurfaceView来显示摄像头流。`SurfaceView`类是一个专用的绘图区域，你可以将其嵌入到你的应用程序中。
- en: 'So for our example, we need to derive a new class from the Android `SurfaceView`
    class (lets call it `CameraPreview`) and implement a `SurfaceHolder.Callback`
    interface. This interface is used to react to any events related to the surface,
    such as the creation, change, and destruction of the surface. Accessing the mobile
    camera is done through the `Camera` class. In the constructor, the Android `Camera`
    instance (defined previously) is passed:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，对于我们的示例，我们需要从Android的`SurfaceView`类派生一个新类（我们称之为`CameraPreview`），并实现`SurfaceHolder.Callback`接口。这个接口用于响应与表面相关的任何事件，例如表面的创建、更改和销毁。通过`Camera`类访问移动摄像头。在构造函数中，传递了之前定义的Android
    `Camera`实例：
- en: '[PRE8]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'In the `surfaceChanged` method, you take care of passing an initialized `SurfaceHolder`
    instance (that is the instance that holds the display surface) and starting the
    preview stream of the camera, which you later want to display (and process) in
    your own application. The stopping of the camera preview stream is important as
    well:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在`surfaceChanged`方法中，你需要处理传递一个初始化的`SurfaceHolder`实例（这是持有显示表面的实例）并开始相机的预览流，你稍后想在你的应用程序中显示（和处理）。停止相机预览流同样重要：
- en: '[PRE9]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The inherited methods, `surfaceCreated()` and `surfaceDestroyed()`, remain empty.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 继承的方法`surfaceCreated()`和`surfaceDestroyed()`保持为空。
- en: 'Having our `CameraPreview` class defined, we can declare it in the `Activity`
    class:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 有了我们定义的`CameraPreview`类，我们可以在`Activity`类中声明它：
- en: '[PRE10]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Then, instantiate it in the `onResume()` method:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在`onResume()`方法中实例化它：
- en: '[PRE11]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'To test your application, you can do the same with your other project: please
    connect your testing device to your computer via a USB cable. In Eclipse, right-click
    on your project folder, `CameraAccessAndroid`, and in the pop-up menu go to **Run
    As** | **1 Android Application**. You should now be able to see the live camera
    view on your mobile screen as soon as the application is uploaded and started.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 要测试你的应用程序，你可以对你的其他项目做同样的操作：请通过USB线将你的测试设备连接到电脑上。在Eclipse中，右键点击你的项目文件夹`CameraAccessAndroid`，在弹出菜单中选择**运行方式**
    | **1 Android应用程序**。现在你应该能在应用程序上传并启动后，在手机屏幕上看到实时的相机视图。
- en: Live camera view in JME
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: JME中的实时相机视图
- en: 'In the preceding example, you got a glimpse of how you can access the Android
    camera with a low-level graphics library (standard Android library). Since we
    want to perform Augmented Reality, we will need to have another technique to overlay
    the virtual content over the video view. There are different ways to do that,
    and the best method is certainly to use a common view, which will integrate the
    virtual and video content nicely. A powerful technique is to use a managed 3D
    graphics library based on a scenegraph model. A scenegraph is basically a data
    structure that helps you to build elaborate 3D scenes more easily than in plain
    OpenGL® by logically organizing basic building blocks, such as geometry or spatial
    transformations. As you installed JME in the first chapter, we will use this specific
    library offering all the characteristics we need for our AR development. In this
    subsection, we will explore how you can use JME to display the video. Different
    to our preceding example, the camera view will be integrated to the 3D scenegraph.
    In order to achieve this, you use the following steps:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，你已经了解了如何使用低级图形库（标准的Android库）访问Android相机。由于我们想要执行增强现实，我们将需要另一种技术将虚拟内容覆盖在视频视图上。有不同的方法可以实现这一点，最好的方法无疑是使用一个公共视图，它将很好地整合虚拟和视频内容。一个强大的技术是使用基于场景图模型的托管3D图形库。场景图基本上是一个数据结构，它可以帮助你比在纯OpenGL®中更容易地构建复杂的3D场景，通过逻辑地组织基本构建块，如几何或空间变换。由于你在第一章中安装了JME，我们将使用这个特定的库，它提供了我们进行AR开发所需的所有特性。在本小节中，我们将探讨如何使用JME显示视频。与前面的示例不同，相机视图将被整合到3D场景图中。为了实现这一点，你需要执行以下步骤：
- en: Create a project with JME support.
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个支持JME的项目。
- en: Create the activity which sets up JME.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个设置JME的活动。
- en: Create the JME application, which does the actual rendering of our 3D scene.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建JME应用程序，它实际渲染我们的3D场景。
- en: For creating the project with JME, you can follow the instructions in the *Installing
    JMonkeyEngine* section of [Chapter 1](ch01.html "Chapter 1. Augmented Reality
    Concepts and Tools"), *Augmented Reality Concepts and Tools*. We will make a new
    project called `CameraAccessJME`.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建支持JME的项目，你可以按照[第1章](ch01.html "第1章. 增强现实概念和工具")中*安装JMonkeyEngine*一节的说明进行操作，*增强现实概念和工具*。我们将创建一个名为`CameraAccessJME`的新项目。
- en: Creating the JME activity
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建JME活动
- en: As an Android developer, you know that an Android activity is the main entry
    point to create your applications. However, JME is a platform-independent game
    engine that runs on many platforms with Java support. The creators of JME wanted
    to ease the process of integrating existing (and new) JME applications into Android
    as easily as possible. Therefore, they explicitly differentiated between the JME
    applications, which do the actual rendering of the scene (and could be used on
    other platforms as well), and the Android specific parts in the JME activity for
    setting up the environment to allow the JME application to run. The way they achieved
    this is to have a specific class called `AndroidHarness`, which takes the burden
    off the developer to configure the Android activity properly. For example, it
    maps touch events on your screen to mouse events in the JME application. One challenge
    in this approach is to forward Android-specific events, which are not common to
    other platforms in the JME application. Don't worry, we will show you how to do
    this for the camera images.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一名Android开发者，您知道Android活动是创建应用程序的主要入口点。然而，JME是一个平台无关的游戏引擎，可以在支持Java的许多平台上运行。JME的创建者希望尽可能简单地将现有的（和新的）JME应用程序集成到Android中。因此，他们明确区分了实际渲染场景的JME应用程序（也可以在其他平台上使用）和JME活动中的Android特定部分，以设置环境允许JME应用程序运行。他们实现这一目标的方法是使用一个特定的类`AndroidHarness`，它减轻了开发者正确配置Android活动的负担。例如，它将屏幕上的触摸事件映射到JME应用程序中的鼠标事件。这种方法中的一个挑战是将Android特定的事件转发到JME应用程序中，这些事件在其他平台上并不常见。别担心，我们将向您展示如何为相机图像实现这一点。
- en: 'The first thing you want to do is create an Android activity derived from the
    `AndroidHarness` class, which we will call the `CameraAccessJMEActivity` method.
    Just like the `CameraAccessAndroidActivity` class, it holds instances of the `Camera`
    and `CameraPreview` classes. In contrast, it will also hold an instance of your
    actual JME application (discussed in the next section of this chapter) responsible
    for rendering your scene. You did not yet provide an actual instance of the class
    but only the fully qualified path name. The instance of your class is constructed
    at runtime through a reflection technique in the `AndroidHarness` super class:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 您要做的第一件事是创建一个派生自`AndroidHarness`类的Android活动，我们将其称为`CameraAccessJMEActivity`方法。它与`CameraAccessAndroidActivity`类相似，包含`Camera`和`CameraPreview`类的实例。不同之处在于，它还将包含您实际的JME应用程序实例（将在本章下一节中讨论），负责渲染场景。您尚未提供类的实际实例，只提供了完整的类路径名。在`AndroidHarness`超类中通过反射技术在运行时构造类的实例：
- en: '[PRE12]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: During runtime, you can then access the actual instance by casting a general
    JME application class, which `AndroidHarness` stores in its `app` variable to
    your specific class, for example, through the `(com.ar4android.CameraAccessJME)`
    app.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行时，您可以通过将通用的JME应用程序类转换为特定的类来访问实际实例，`AndroidHarness`将其存储在`app`变量中，例如，通过`(com.ar4android.CameraAccessJME)`
    app。
- en: 'As discussed at the beginning of this chapter, the camera can deliver the images
    in various pixel formats. Most rendering engines (and JME is no exception) cannot
    handle the wide variety of pixel formats but expect certain formats such as RGB565\.
    The RGB565 format stores the red and blue components in 5 bits and the green component
    in 6 bits, thereby displaying 65536 colors in 16 bits per pixel. You can check
    if your camera supports this format in the `initializeCameraParameters` method
    by adding the following code:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 如本章开头所讨论的，相机可以以各种像素格式提供图像。大多数渲染引擎（JME也不例外）无法处理各种像素格式，但期望某些格式，如RGB565。RGB565格式以5位存储红色和蓝色分量，以6位存储绿色分量，从而在16位每像素的情况下显示65536种颜色。您可以在`initializeCameraParameters`方法中通过添加以下代码来检查相机是否支持此格式：
- en: '[PRE13]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: In this code snippet, we query all available pixel formats (iterating over `parameters.
    getSupportedPreviewFormats()`) and set the pixel format of the RGB565 model if
    supported (and remember that we did this by setting the flag `pixelFormatConversionNeeded`).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在这段代码中，我们查询所有可用的像素格式（遍历`parameters.getSupportedPreviewFormats()`）并在支持的情况下设置RGB565模型的像素格式（记住，我们是通过对`pixelFormatConversionNeeded`标志进行设置来完成这一步的）。
- en: 'As mentioned before, in contrast to the previous example, we will not directly
    render the `SurfaceView` class. Instead, we will copy the preview images from
    the camera in each frame. To prepare for this, we define the `preparePreviewCallbackBuffer()`
    method, which you will call in the `onResume()` method after creating your camera
    and setting its parameters. It allocates buffers to copy the camera images and
    forwarding it to JME:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，与上一个示例不同，我们不会直接渲染`SurfaceView`类。相反，我们将在每一帧中从摄像头复制预览图像。为此，我们定义了`preparePreviewCallbackBuffer()`方法，你可以在创建摄像头并设置其参数后，在`onResume()`方法中调用它。它分配缓冲区以复制摄像头图像并将其转发给JME：
- en: '[PRE14]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: If your camera does not support RGB565, it may deliver the frame in the YCbCr
    format (Luminance, blue difference, red difference), which you have to convert
    to the RGB565 format. To do that, we will use a color space conversion method,
    which is really common in AR and for image processing. We provide an implementation
    of this method (`yCbCrToRGB565(…)`) available in the sample project. A basic approach
    to use this method is to create different image buffers, where you will copy the
    source, intermediate, and final transformed image.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的摄像头不支持RGB565格式，它可能会以YCbCr格式（亮度、蓝色差、红色差）输出帧，这就需要你将其转换为RGB565格式。为此，我们将使用一种在AR和图像处理中非常常见的色彩空间转换方法。我们在示例项目中提供了一个此方法的实现（`yCbCrToRGB565(…)`）。使用这个方法的基本步骤是创建不同的图像缓冲区，你将在其中复制源图像、中间图像和最终转换后的图像。
- en: So for the conversion, the `mPreviewWidth`, `mPreviewHeight`, and `bitsPerPixel`
    variables are queried by calling the `getParameters()` method of your camera instance
    in the `preparePreviewCallbackBuffer()` method and determine the size of your
    byte arrays holding the image data. You will pass a JME image (`cameraJMEImageRGB565`)
    to the JME application, which is constructed from a Java `ByteBuffer` class, which
    itself just wraps the RGB565 byte array.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在进行转换时，通过在`preparePreviewCallbackBuffer()`方法中调用摄像头实例的`getParameters()`方法来查询`mPreviewWidth`、`mPreviewHeight`和`bitsPerPixel`变量，并确定持有图像数据的字节数组的大小。你将一个JME图像（`cameraJMEImageRGB565`）传递给JME应用程序，这个图像是由Java的`ByteBuffer`类构造的，它只是简单地包装了RGB565字节数组。
- en: 'Having prepared the image buffers, we now need to access the content of the
    actual image. In Android, you do this by an implementation of the `Camera.PreviewCallback`
    interface. In the `onPreviewFrame(byte[] data, Camera c)` method of this object,
    you can get access to the actual camera image stored as a byte array:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 准备好图像缓冲区后，我们现在需要访问实际图像的内容。在Android中，你通过实现`Camera.PreviewCallback`接口来完成这个操作。在这个对象的`onPreviewFrame(byte[]
    data, Camera c)`方法中，你可以获取到实际存储为字节数组的摄像头图像：
- en: '[PRE15]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The `setTexture` method of the `CameraAccessJME` class simply copies the incoming
    data into a local image object.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '`CameraAccessJME`类的`setTexture`方法仅仅是将传入的数据复制到一个本地图像对象中。'
- en: 'Finally, you register your implementation of the `Camera.PreviewCallback` interface
    in the `onSurfaceChanged()` method of the `CameraPreview` class:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你需要在`CameraPreview`类的`onSurfaceChanged()`方法中注册你的`Camera.PreviewCallback`接口实现：
- en: '[PRE16]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Note
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: A faster method to retrieve the camera images, which avoids creating a new buffer
    in each frame, is to allocate a buffer before and use it with the methods, `mCamera.addCallbackBuffer()`
    and `mCamera.setPreviewCallbackWithBuffer()`. Please note that this approach might
    be incompatible with some devices.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 一种更快的方法来获取摄像头图像，避免在每一帧都创建新缓冲区，是在之前分配一个缓冲区，并使用`mCamera.addCallbackBuffer()`和`mCamera.setPreviewCallbackWithBuffer()`方法。请注意，这种方法可能与某些设备不兼容。
- en: Creating the JME application
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建JME应用程序
- en: 'As mentioned in the preceding section, the JME application is the place where
    the actual rendering of the scene takes place. It should not concern itself with
    the nitty-gritty details of the Android system, which were described earlier.
    JME provides you with a convenient way to initialize your application with many
    default settings. All you have to do is inherit from the `SimpleApplication` class,
    initialize your custom variables in `simpleInitApp()`, and eventually update them
    before a new frame is rendered in the `simpleUpdate()` method. For our purpose
    of rendering the camera background, we will create a custom `ViewPort` (a view
    inside the display window), and a virtual `Camera` (for rendering the observed
    scene), in the `initVideoBackground` method. The common method to display the
    video in a scene graph such as JME is to use the video image as a texture, which
    is placed on a quadrilateral mesh:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一部分所述，JME应用程序是实际进行场景渲染的地方。它不应该关注前面描述的Android系统的细节。JME为你提供了一种方便的方法，使用许多默认设置初始化你的应用程序。你需要做的就是从`SimpleApplication`类继承，在`simpleInitApp()`中初始化你的自定义变量，并在`simpleUpdate()`方法中在渲染新帧之前更新它们。为了我们的渲染相机背景的目的，我们将在`initVideoBackground`方法中创建一个自定义`ViewPort`（显示窗口内的视图）和一个虚拟`Camera`（用于渲染观察到的场景）。在JME这样的场景图中显示视频的常见方法是将视频图像作为纹理，放置在一个四边形网格上：
- en: '[PRE17]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Let's have a more detailed look at this essential method for setting up our
    scenegraph for the rendering of the video background. You first create a quad
    shape and assign it to a JME `Geometry` object. To assure correct mapping between
    the screen and the camera, you scale and reposition the geometry according to
    the dimensions of the device's screen. You assign a material to the quad and also
    create a texture for it. Since we are doing 3D rendering, we need to define the
    camera looking at this quad. As we want the camera to only see the quad nicely
    placed in front of the camera without distortion, we create a custom viewport
    and an orthographic camera (this orthographic camera has no perspective foreshortening).
    Finally, we add the quad geometry to this viewport.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地看看这个为设置视频背景渲染场景图的基本方法。首先，你创建一个四边形形状，并将其分配给一个JME `Geometry`对象。为了确保屏幕与相机之间的正确映射，你会根据设备屏幕的尺寸缩放和重新定位几何图形。你为四边形分配一个材质，并为它创建一个纹理。由于我们进行的是3D渲染，我们需要定义一个观察这个四边形的相机。由于我们希望相机仅在没有失真的情况下，很好地放置在相机前方的四边形，因此我们创建了一个自定义视口和一个正交相机（这种正交相机没有透视缩短效果）。最后，我们将四边形几何添加到这个视口中。
- en: 'Now, we have our camera looking at the textured quad rendered fullscreen. All
    that is left to do is update the texture of the quad each time a new video frame
    is available from the camera. We will do this in the `simpleUpdate()` method,
    which is called regularly by the JME rendering engine:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们的相机观察的是全屏渲染的带纹理四边形。剩下的就是每次相机有新的视频帧可用时，更新四边形的纹理。我们将在`simpleUpdate()`方法中这样做，该方法由JME渲染引擎定期调用：
- en: '[PRE18]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: You may have noted the usage of the conditional test on the `mNewCameraFrameAvailable`
    variable. As the scenegraph renders its content with a different refresh rate
    (up to 60 fps, on a modern smartphone) than what a mobile camera can normally
    deliver (typically 20-30 fps), we use the `mNewCameraFrameAvailable` flag to only
    update the texture if a new image becomes available.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能注意到了对`mNewCameraFrameAvailable`变量的条件测试的使用。由于场景图以其内容的不同刷新率（在现代智能手机上高达60 fps）进行渲染，而移动相机通常能提供的刷新率（通常是20-30
    fps）不同，我们使用`mNewCameraFrameAvailable`标志来更新纹理，仅当有新图像可用时。
- en: 'So this is it. With these steps implemented, you can compile and upload your
    application and should get a similar result as shown in the following figure:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是全部内容。实施这些步骤后，你可以编译并上传你的应用程序，并应得到与下图类似的结果：
- en: '![Creating the JME application](img/8553OS_02_04.jpg)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![创建JME应用程序](img/8553OS_02_04.jpg)'
- en: Summary
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter you got an introduction to the world of Android camera access
    and how to display camera images in the JME 3D rendering engine. You learned about
    various camera parameters and the compromises you have made (for example, between
    image size and frames per second) to get an efficient camera access. We also introduced
    the simplest way of displaying a camera view in an Android activity, but also
    explained why you need to go beyond this simple example to integrate the camera
    view and 3D graphics in a single application. Finally, we helped you through the
    implementation of a JME application, which renders the camera background. The
    knowledge you gained in this chapter is the beneficial basis to overlay the first
    3D objects on the camera view—a topic we will discuss in the next chapter.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您了解了Android相机访问的世界以及如何在JME 3D渲染引擎中显示相机图像。您学习了各种相机参数以及为了获得有效的相机访问所做出的妥协（例如，在图像大小和每秒帧数之间）。我们还介绍了在Android活动中显示相机视图的最简单方法，但也解释了为什么需要超越这个简单示例，将相机视图和3D图形在单一应用程序中集成。最后，我们帮助您实现了渲染相机背景的JME应用程序。您在本章中获得的知识是为相机视图叠加第一个3D对象的有益基础——这是我们将在下一章讨论的主题。
